# é˜¿ç§‹
# 2025/09/18 14:29
import io
import base64
import asyncio
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from dotenv import load_dotenv
from pdf2image import convert_from_bytes
from PIL import Image
import aiohttp
import json
from pathlib import Path
import os
from urllib.parse import urlparse

# ============ é…ç½®éƒ¨åˆ† ============
load_dotenv(f"D:\Pycharm_project\my_multimodal_RAG\\backend\.env", override=True)
API_KEY = os.getenv("QWEN_API_KEY")
MODEL_NAME = os.getenv("QWEN_MULTIMODAL_MODAL_NAME")
MODEL_URL = os.getenv("QWEN_BASE_URL")

# æ‰¹å¤„ç†é…ç½®
PAGES_PER_REQUEST = 2
CONCURRENT_REQUESTS = 1


@dataclass
class ExtractionResult:
    """æå–ç»“æœæ•°æ®ç±»"""
    filename: str = ""  # æ·»åŠ é»˜è®¤å€¼
    markdown_content: str = ""
    tables: List[Dict[str, Any]] = None
    formulas: List[Dict[str, Any]] = None
    metadata: Dict[str, Any] = None
    token_usage: Dict[str, int] = None
    time_cost: Dict[str, float] = None
    page_images: List[Image.Image] = None
    per_page_results: List[Dict[str, Any]] = None

    def __post_init__(self):
        if self.tables is None:
            self.tables = []
        if self.formulas is None:
            self.formulas = []
        if self.metadata is None:
            self.metadata = {}
        if self.token_usage is None:
            self.token_usage = {}
        if self.time_cost is None:
            self.time_cost = {}
        if self.page_images is None:
            self.page_images = []
        if self.per_page_results is None:
            self.per_page_results = []


class PDFMultimodalExtractor:
    """PDFå¤šæ¨¡æ€ä¿¡æ¯æŠ½å–å™¨"""

    def __init__(
            self,
            model_url: str = MODEL_URL,
            api_key: str = API_KEY,
            model_name: str = MODEL_NAME,
            pages_per_request: int = PAGES_PER_REQUEST
    ):
        self.model_url = model_url
        self.api_key = api_key
        self.model_name = model_name
        self.dpi = 100
        self.pages_per_request = pages_per_request

        # æ£€æµ‹APIç±»å‹
        self.api_type = self._detect_api_type()
        print(f"âœ“ æ£€æµ‹åˆ°APIç±»å‹: {self.api_type}")

        # å¦‚æœä½¿ç”¨OpenAI SDKï¼Œåˆå§‹åŒ–å®¢æˆ·ç«¯
        if self.api_type == "openai_sdk":
            from openai import AsyncOpenAI
            if "/chat/completions" in model_url:
                base_url = model_url.replace("/chat/completions", "")
            else:
                base_url = model_url
            self.openai_client = AsyncOpenAI(api_key=api_key, base_url=base_url)
            print(f"  ä½¿ç”¨OpenAI SDK (base_url: {base_url})")
        else:
            self.openai_client = None
            print(f"  ä½¿ç”¨HTTPå®¢æˆ·ç«¯ (url: {model_url})")

        self.total_prompt_tokens = 0
        self.total_completion_tokens = 0
        self.total_tokens = 0

        self.pdf_convert_time = 0
        self.api_call_time = 0
        self.total_time = 0

    def _detect_api_type(self) -> str:
        """æ£€æµ‹APIç±»å‹ï¼šopenai_sdk, qwen, claude"""
        url_lower = self.model_url.lower()

        # é€šä¹‰åƒé—®/DashScope
        if "dashscope" in url_lower or "aliyun" in url_lower:
            return "qwen"

        # Claude API
        if "anthropic" in url_lower or "claude" in url_lower:
            return "claude"

        # OpenAIå®˜æ–¹æˆ–ä½¿ç”¨OpenAI SDK
        if any(x in url_lower for x in ["openai.com", "api.openai.com", "oai.azure.com"]):
            return "openai_sdk"

        # å¦‚æœæ¨¡å‹ååŒ…å«gptï¼Œä½¿ç”¨OpenAI SDKï¼ˆå…¼å®¹ç¬¬ä¸‰æ–¹ä»£ç†ï¼‰
        if "gpt" in self.model_name.lower():
            return "openai_sdk"

        # é»˜è®¤ä½¿ç”¨Claudeæ ¼å¼
        return "claude"

    def _get_request_url(self) -> str:
        """è¿”å›å®é™…è¦POSTçš„å®Œæ•´URL"""
        url = self.model_url
        lower = url.lower()

        # å·²åŒ…å«å®Œæ•´ç«¯ç‚¹ï¼Œç›´æ¥è¿”å›
        if any(x in lower for x in ["/chat/completions", "/v1/completions", "completions"]):
            return url

        # DashScopeå…¼å®¹æ¨¡å¼URL
        if "dashscope" in lower and "compatible-mode" in lower:
            if not url.endswith("/chat/completions"):
                return url.rstrip('/') + '/chat/completions'
            return url

        # ç±»ä¼¼ https://host/.../v1 æ ¼å¼ï¼Œè¡¥ä¸Š chat/completions
        parsed = urlparse(url)
        path = parsed.path or ""
        if path.rstrip('/') == '/v1':
            return url.rstrip('/') + '/chat/completions'

        return url

    def pdf_to_images(self, pdf_path: str) -> List[Image.Image]:
        """å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨"""
        with open(pdf_path, 'rb') as f:
            pdf_content = f.read()
        images = convert_from_bytes(pdf_content, dpi=self.dpi)
        return images

    def image_to_base64(self, image: Image.Image, max_size: int = 2000) -> str:
        """å°†PIL Imageè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²ï¼Œå¹¶å‹ç¼©å›¾ç‰‡"""
        if image.width > max_size or image.height > max_size:
            image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)

        buffer = io.BytesIO()
        if image.mode == 'RGBA':
            image = image.convert('RGB')
        image.save(buffer, format='JPEG', quality=85)
        buffer.seek(0)
        return base64.b64encode(buffer.read()).decode('utf-8')

    async def call_multimodal_api_openai_sdk(
            self,
            image_base64_list: List[str],
            page_nums: List[int],
            total_pages: int
    ) -> Dict[str, Any]:
        """ä½¿ç”¨OpenAIå®˜æ–¹SDKè°ƒç”¨APIï¼ˆé€‚ç”¨äºGPTç³»åˆ—ï¼‰"""
        import time
        start_time = time.time()

        page_range = f"{page_nums[0]}-{page_nums[-1]}" if len(page_nums) > 1 else str(page_nums[0])

        prompt = self._get_extraction_prompt(page_range, total_pages, page_nums)

        # æ„å»ºæ¶ˆæ¯å†…å®¹ - OpenAIæ ¼å¼
        content_items = [{"type": "text", "text": prompt}]

        for img_base64 in image_base64_list:
            content_items.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{img_base64}"
                }
            })

        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PDFæ–‡æ¡£ä¿¡æ¯æå–åŠ©æ‰‹ã€‚ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—æˆ–markdownä»£ç å—æ ‡è®°ã€‚ç›´æ¥è¿”å›å¯è§£æçš„JSONå¯¹è±¡ã€‚"
            },
            {"role": "user", "content": content_items}
        ]

        try:
            response = await self.openai_client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=4096,
                temperature=0.1,
                response_format={"type": "json_object"}
            )

            # æå–Tokenä½¿ç”¨ä¿¡æ¯
            if response.usage:
                prompt_tokens = response.usage.prompt_tokens
                completion_tokens = response.usage.completion_tokens
                total_tokens = response.usage.total_tokens

                self.total_prompt_tokens += prompt_tokens
                self.total_completion_tokens += completion_tokens
                self.total_tokens += total_tokens

                print(f"  ç¬¬{page_range}é¡µ Token: è¾“å…¥={prompt_tokens}, è¾“å‡º={completion_tokens}, æ€»è®¡={total_tokens}")

            content = response.choices[0].message.content

            api_time = time.time() - start_time
            print(f"  ç¬¬{page_range}é¡µ è€—æ—¶: {api_time:.2f}ç§’")

            return self._parse_response_content(content, page_nums)

        except Exception as e:
            print(f"âŒ OpenAI SDKè°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}")
            raise

    async def call_multimodal_api_qwen(
            self,
            image_base64_list: List[str],
            page_nums: List[int],
            total_pages: int
    ) -> Dict[str, Any]:
        """è°ƒç”¨é€šä¹‰åƒé—®APIï¼ˆDashScopeå…¼å®¹æ¨¡å¼ï¼‰"""
        import time
        start_time = time.time()

        page_range = f"{page_nums[0]}-{page_nums[-1]}" if len(page_nums) > 1 else str(page_nums[0])

        prompt = self._get_extraction_prompt(page_range, total_pages, page_nums)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        # æ„å»ºæ¶ˆæ¯å†…å®¹ - é€šä¹‰åƒé—®æ ¼å¼
        content_items = [{"type": "text", "text": prompt}]

        # å…³é”®ä¿®å¤ï¼šé€šä¹‰åƒé—®ä½¿ç”¨ image_url ç±»å‹ï¼Œè€Œä¸æ˜¯ image ç±»å‹
        for img_base64 in image_base64_list:
            content_items.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{img_base64}"
                }
            })

        payload = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PDFæ–‡æ¡£ä¿¡æ¯æå–åŠ©æ‰‹ã€‚ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—æˆ–markdownä»£ç å—æ ‡è®°ã€‚"
                },
                {"role": "user", "content": content_items}
            ],
            "max_tokens": 4096,
            "temperature": 0.1
        }

        payload_size = len(json.dumps(payload))
        print(f"  è¯·æ±‚ä½“å¤§å°: {payload_size / 1024 / 1024:.2f} MB")

        request_url = self._get_request_url()
        print(f"  è¯·æ±‚URL: {request_url}")

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                        request_url,
                        headers=headers,
                        json=payload,
                        timeout=aiohttp.ClientTimeout(total=300)
                ) as response:
                    response_text = await response.text()

                    if response.status != 200:
                        display_text = response_text[:1000]
                        print(f"âŒ APIé”™è¯¯: {response.status}")
                        print(f"é”™è¯¯è¯¦æƒ…: {display_text}")
                        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status} - {display_text}")

                    result = await response.json()

                    # æå–Tokenä½¿ç”¨ä¿¡æ¯
                    if 'usage' in result:
                        usage = result['usage']
                        prompt_tokens = usage.get('prompt_tokens', 0)
                        completion_tokens = usage.get('completion_tokens', 0)
                        total_tokens = usage.get('total_tokens', 0)

                        self.total_prompt_tokens += prompt_tokens
                        self.total_completion_tokens += completion_tokens
                        self.total_tokens += total_tokens

                        print(
                            f"  ç¬¬{page_range}é¡µ Token: è¾“å…¥={prompt_tokens}, è¾“å‡º={completion_tokens}, æ€»è®¡={total_tokens}")

                    # æå–å“åº”å†…å®¹
                    content = result['choices'][0]['message']['content']

                    api_time = time.time() - start_time
                    print(f"  ç¬¬{page_range}é¡µ è€—æ—¶: {api_time:.2f}ç§’")

                    return self._parse_response_content(content, page_nums)

        except asyncio.TimeoutError:
            print(f"âŒ è¯·æ±‚è¶…æ—¶ï¼ˆé¡µé¢ {page_range}ï¼‰")
            raise
        except Exception as e:
            print(f"âŒ é€šä¹‰åƒé—®APIè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
            raise

    async def call_multimodal_api_claude(
            self,
            image_base64_list: List[str],
            page_nums: List[int],
            total_pages: int
    ) -> Dict[str, Any]:
        """è°ƒç”¨Claude API"""
        import time
        start_time = time.time()

        page_range = f"{page_nums[0]}-{page_nums[-1]}" if len(page_nums) > 1 else str(page_nums[0])

        prompt = self._get_extraction_prompt(page_range, total_pages, page_nums)

        headers = {
            "Content-Type": "application/json",
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01"
        }

        # æ„å»ºæ¶ˆæ¯å†…å®¹ - Claudeæ ¼å¼
        claude_content = []
        for img_base64 in image_base64_list:
            claude_content.append({
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",
                    "data": img_base64
                }
            })
        claude_content.append({"type": "text", "text": prompt})

        payload = {
            "model": self.model_name,
            "max_tokens": 4096,
            "temperature": 0.1,
            "system": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PDFæ–‡æ¡£ä¿¡æ¯æå–åŠ©æ‰‹ã€‚ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¿”å›ç»“æœã€‚",
            "messages": [{"role": "user", "content": claude_content}]
        }

        payload_size = len(json.dumps(payload))
        print(f"  è¯·æ±‚ä½“å¤§å°: {payload_size / 1024 / 1024:.2f} MB")
        print(f"  è¯·æ±‚URL: {self.model_url}")

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                        self.model_url,
                        headers=headers,
                        json=payload,
                        timeout=aiohttp.ClientTimeout(total=300)
                ) as response:
                    response_text = await response.text()

                    if response.status != 200:
                        display_text = response_text[:1000]
                        print(f"âŒ APIé”™è¯¯: {response.status}")
                        print(f"é”™è¯¯è¯¦æƒ…: {display_text}")
                        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status} - {display_text}")

                    result = await response.json()

                    # æå–Tokenä½¿ç”¨ä¿¡æ¯
                    if 'usage' in result:
                        usage = result['usage']
                        prompt_tokens = usage.get('input_tokens', 0)
                        completion_tokens = usage.get('output_tokens', 0)
                        total_tokens = prompt_tokens + completion_tokens

                        self.total_prompt_tokens += prompt_tokens
                        self.total_completion_tokens += completion_tokens
                        self.total_tokens += total_tokens

                        print(
                            f"  ç¬¬{page_range}é¡µ Token: è¾“å…¥={prompt_tokens}, è¾“å‡º={completion_tokens}, æ€»è®¡={total_tokens}")

                    # æå–å“åº”å†…å®¹
                    content = result['content'][0]['text']

                    api_time = time.time() - start_time
                    print(f"  ç¬¬{page_range}é¡µ è€—æ—¶: {api_time:.2f}ç§’")

                    return self._parse_response_content(content, page_nums)

        except asyncio.TimeoutError:
            print(f"âŒ è¯·æ±‚è¶…æ—¶ï¼ˆé¡µé¢ {page_range}ï¼‰")
            raise
        except Exception as e:
            print(f"âŒ Claude APIè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
            raise

    def _get_extraction_prompt(self, page_range: str, total_pages: int, page_nums: List[int]) -> str:
        """ç”Ÿæˆæå–æŒ‡ä»¤çš„prompt"""

        # æ„å»ºå›¾ç‰‡å’Œé¡µç çš„å¯¹åº”è¯´æ˜
        if len(page_nums) == 1:
            page_mapping = f"è¿™å¼ å›¾ç‰‡æ˜¯ç¬¬{page_nums[0]}é¡µ"
        else:
            mappings = [f"ç¬¬{i + 1}å¼ å›¾ç‰‡æ˜¯ç¬¬{page_num}é¡µ" for i, page_num in enumerate(page_nums)]
            page_mapping = "ï¼Œ".join(mappings)

        # æ„å»ºæ¯é¡µçš„IDå‰ç¼€è¯´æ˜
        id_examples = []
        for page_num in page_nums:
            id_examples.append(f"ç¬¬{page_num}é¡µçš„å…ƒç´ IDæ ¼å¼ï¼šè¡¨æ ¼{page_num}-1ã€å…¬å¼{page_num}-1ã€å›¾ç‰‡{page_num}-1")
        id_format_desc = "ï¼›".join(id_examples)

        return f"""
        ã€é‡è¦ã€‘è¯·ç›´æ¥åˆ†æå›¾ç‰‡å†…å®¹å¹¶è¿”å›JSONï¼Œä¸è¦è¯´"æˆ‘æ— æ³•æå–"æˆ–ç»™å‡ºä»»ä½•è§£é‡Šã€‚

        **å›¾ç‰‡å’Œé¡µç å¯¹åº”å…³ç³»ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š**
        {page_mapping}
        
        åˆ†æè¿™äº›PDFé¡µé¢ï¼ˆç¬¬{page_range}é¡µï¼Œå…±{total_pages}é¡µï¼‰ï¼š
        
        **æ ¸å¿ƒè¦æ±‚ï¼š**
        - **æ¯é¡µmarkdownå¼€å¤´å¿…é¡»æ˜¯æ ‡é¢˜ `{{ç¬¬Xé¡µ}}`**ï¼ˆXæ˜¯è¯¥é¡µçš„å®é™…é¡µç ï¼Œç”¨äºéªŒè¯ï¼‰
        - **æ‰€æœ‰å†…å®¹ï¼ˆå›¾ç‰‡ã€è¡¨æ ¼ã€å…¬å¼ï¼‰å¿…é¡»ç›´æ¥åµŒå…¥åˆ°markdownä¸­åŸæœ‰ä½ç½®**
        - å›¾ç‰‡ä½¿ç”¨markdownè¯­æ³•ï¼š`![å›¾ç‰‡æè¿°](placeholder)`ï¼Œæè¿°è¦è¯¦ç»†
        - è¡¨æ ¼ä½¿ç”¨markdownè¡¨æ ¼è¯­æ³•ç›´æ¥åµŒå…¥
        - å…¬å¼ä½¿ç”¨LaTeXè¯­æ³•ï¼ˆè¡Œå†…ç”¨$...$ï¼Œç‹¬ç«‹ç”¨$$...$$ï¼‰ç›´æ¥åµŒå…¥
        - ä¿æŒå†…å®¹çš„åŸå§‹é¡ºåºå’Œä½ç½®å…³ç³»
        
        1. **Markdownå†…å®¹ï¼ˆæœ€é‡è¦ï¼‰**ï¼š
           - **æ¯é¡µå¼€å¤´å¿…é¡»æ˜¯ `## ç¬¬Xé¡µ`**ï¼ˆç”¨äºé¡µé¢è¯†åˆ«å’ŒéªŒè¯ï¼‰
           - è¯†åˆ«æ‰€æœ‰æ ‡é¢˜å±‚çº§ï¼ˆ# ## ###ï¼‰
           - ä¿æŒæ®µè½ç»“æ„å’Œæ ¼å¼
           - ä¿ç•™åˆ—è¡¨ã€å¼•ç”¨
           - **å›¾ç‰‡å¿…é¡»åœ¨åŸä½ç½®æ’å…¥**ï¼šç”¨`![è¯¦ç»†æè¿°](placeholder)`è¡¨ç¤º
           - **è¡¨æ ¼å¿…é¡»åœ¨åŸä½ç½®æ’å…¥**ï¼šä½¿ç”¨markdownè¡¨æ ¼è¯­æ³•
           - **å…¬å¼å¿…é¡»åœ¨åŸä½ç½®æ’å…¥**ï¼šä½¿ç”¨LaTeXè¯­æ³•
           - å¿½ç•¥é¡µçœ‰å’Œé¡µè„šå†…å®¹
           - å¦‚æœåˆ†æå¤šé¡µï¼Œé¡µé—´ç”¨ `---` åˆ†éš”
        
        2. **å…ƒç´ IDå‘½åè§„åˆ™ï¼ˆéå¸¸é‡è¦ï¼‰**ï¼š
           {id_format_desc}
           - åŒä¸€é¡µå†…çš„å…ƒç´ æŒ‰å‡ºç°é¡ºåºç¼–å·ï¼š-1ã€-2ã€-3...
        
        3. **è¡¨æ ¼æå–ï¼ˆç”¨äºå…ƒæ•°æ®ç»Ÿè®¡ï¼‰**ï¼š
           - æå–æ‰€æœ‰è¡¨æ ¼çš„ç»“æ„åŒ–æ•°æ®
           - IDæ ¼å¼å¿…é¡»æ˜¯ï¼šè¡¨æ ¼{{é¡µç }}-{{åºå·}}
           - æ ‡æ³¨æ‰€åœ¨é¡µç ï¼ˆpageå­—æ®µå¿…é¡»å‡†ç¡®ï¼‰
        
        4. **å…¬å¼æå–ï¼ˆç”¨äºå…ƒæ•°æ®ç»Ÿè®¡ï¼‰**ï¼š
           - æå–æ‰€æœ‰æ•°å­¦å…¬å¼
           - IDæ ¼å¼å¿…é¡»æ˜¯ï¼šå…¬å¼{{é¡µç }}-{{åºå·}}
           - ä½¿ç”¨LaTeXæ ¼å¼
           - æ ‡æ³¨æ‰€åœ¨é¡µç ï¼ˆpageå­—æ®µå¿…é¡»å‡†ç¡®ï¼‰
        
        5. **å›¾ç‰‡æè¿°ï¼ˆç”¨äºå…ƒæ•°æ®ç»Ÿè®¡ï¼‰**ï¼š
           - æè¿°æ‰€æœ‰éè¡¨æ ¼ã€éå…¬å¼çš„å›¾åƒå†…å®¹
           - IDæ ¼å¼å¿…é¡»æ˜¯ï¼šå›¾ç‰‡{{é¡µç }}-{{åºå·}}
           - æ ‡æ³¨æ‰€åœ¨é¡µç ï¼ˆpageå­—æ®µå¿…é¡»å‡†ç¡®ï¼‰
           - æ ¹æ®å›¾ç‰‡ç±»å‹æä¾›ä¸åŒè¯¦ç»†ç¨‹åº¦çš„æè¿°ï¼š
             - æ•°æ®å›¾ï¼ˆæŸ±çŠ¶å›¾ã€æŠ˜çº¿å›¾ã€é¥¼å›¾ç­‰ï¼‰ï¼šéœ€è¯¦ç»†æè¿°æ•°æ®è¶‹åŠ¿ã€å…³é”®æ•°å€¼ã€åæ ‡è½´å«ä¹‰ç­‰
             - æµç¨‹å›¾/æ¶æ„å›¾ï¼šéœ€æè¿°å„ç»„æˆéƒ¨åˆ†åŠå…¶å…³ç³»
             - ç…§ç‰‡ï¼šæè¿°ä¸»è¦å¯¹è±¡ã€åœºæ™¯å’Œå†…å®¹
             - ç¤ºæ„å›¾ï¼šæè¿°æ‰€è¡¨è¾¾çš„æ¦‚å¿µæˆ–åŸç†
        
        **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š**
        - ç›´æ¥è¿”å›çº¯JSONå¯¹è±¡
        - ä¸è¦ç”¨```jsonæˆ–```åŒ…è£¹
        - ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—
        - page_numå­—æ®µå¿…é¡»å‡†ç¡®å¡«å†™é¡µç 
        
        **JSONç»“æ„ï¼š**
        {{
            "pages": [
                {{
                    "page_num": {page_nums[0]},
                    "markdown": "## ç¬¬{page_nums[0]}é¡µ\\n\\nè¯¥é¡µå®Œæ•´å†…å®¹...",
                    "page_title": "ä¸»æ ‡é¢˜æˆ–ç©ºå­—ç¬¦ä¸²"
                }}
            ],
            "tables": [
                {{
                    "page": {page_nums[0]},
                    "id": "è¡¨æ ¼{page_nums[0]}-1",
                    "caption": "è¡¨æ ¼æ ‡é¢˜",
                    "content": "markdownè¡¨æ ¼",
                    "data": [["å•å…ƒæ ¼"]]
                }}
            ],
            "formulas": [
                {{
                    "page": {page_nums[0]},
                    "id": "å…¬å¼{page_nums[0]}-1",
                    "latex": "LaTeXå…¬å¼",
                    "type": "inlineæˆ–display",
                    "context": "å‰åæ–‡æœ¬"
                }}
            ],
            "images": [
                {{
                    "page": {page_nums[0]},
                    "id": "å›¾ç‰‡{page_nums[0]}-1",
                    "description": "æ ¹æ®å›¾ç‰‡ç±»å‹æä¾›ç›¸åº”è¯¦ç»†ç¨‹åº¦çš„æè¿°",
                    "type": "chart/graph/photo/diagram",
                    "context": "ä¸Šä¸‹æ–‡"
                }}
            ]
        }}
        
        ç°åœ¨è¯·åˆ†æå›¾ç‰‡å¹¶ç›´æ¥è¿”å›ä¸Šè¿°JSONç»“æ„ï¼š"""

    def _parse_response_content(self, content: str, page_nums: List[int]) -> Dict[str, Any]:
        """è§£æAPIå“åº”å†…å®¹ - å¢å¼ºç‰ˆ"""
        try:
            # æ¸…ç†å†…å®¹
            content = content.strip()

            # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
            if content.startswith('```json'):
                content = content[7:]
            elif content.startswith('```'):
                content = content[3:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()

            # ğŸ”¥ æ–°å¢ï¼šå¦‚æœå†…å®¹ä¸­åŒ…å«éJSONå‰ç¼€ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
            first_brace = content.find('{')
            last_brace = content.rfind('}')

            if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
                # æå–JSONéƒ¨åˆ†
                json_content = content[first_brace:last_brace + 1]

                # å¦‚æœå‰é¢æœ‰éJSONå†…å®¹ï¼Œæ‰“å°è­¦å‘Š
                if first_brace > 0:
                    prefix = content[:first_brace].strip()
                    if prefix:
                        print(f"  âš ï¸  æ£€æµ‹åˆ°JSONå‰æœ‰é¢å¤–å†…å®¹ï¼ˆ{len(prefix)}å­—ç¬¦ï¼‰ï¼Œå·²è‡ªåŠ¨ç§»é™¤")
                        print(f"     å‰ç¼€é¢„è§ˆ: {prefix[:100]}...")

                content = json_content

            parsed = json.loads(content)

            # éªŒè¯å’Œä¿®æ­£page_num
            pages_data = parsed.get('pages', [])
            len_pages_data = len(pages_data)
            print(f"  ğŸ“‹ æ”¶åˆ° {len_pages_data} ä¸ªé¡µé¢æ•°æ®ï¼Œé¢„æœŸé¡µç : {page_nums}")
            if len_pages_data == 0:
                pass

            for i, page_data in enumerate(pages_data):
                returned_page_num = page_data.get('page_num')
                expected_page_num = page_nums[i] if i < len(page_nums) else None

                if returned_page_num != expected_page_num:
                    print(
                        f"  âš ï¸  é¡µé¢{i + 1}: å¤§æ¨¡å‹è¿”å›page_num={returned_page_num}, é¢„æœŸ={expected_page_num}, å·²è‡ªåŠ¨ä¿®æ­£")
                    page_data['page_num'] = expected_page_num
                else:
                    print(f"  âœ“ é¡µé¢{i + 1}: page_num={returned_page_num} åŒ¹é…æ­£ç¡®")

                # äºŒæ¬¡éªŒè¯ï¼šæ£€æŸ¥markdownå¼€å¤´æ˜¯å¦æœ‰é¡µç æ ‡é¢˜
                markdown = page_data.get('markdown', '')
                if markdown.strip().startswith('## ç¬¬'):
                    # å°è¯•ä»markdownä¸­æå–é¡µç 
                    import re
                    match = re.match(r'##\s*ç¬¬(\d+)é¡µ', markdown.strip())
                    if match:
                        markdown_page_num = int(match.group(1))
                        if markdown_page_num != expected_page_num:
                            print(f"  âš ï¸  Markdownæ ‡é¢˜æ˜¾ç¤ºç¬¬{markdown_page_num}é¡µï¼Œä½†é¢„æœŸæ˜¯ç¬¬{expected_page_num}é¡µ")

            # éªŒè¯tablesã€formulasã€imagesçš„pageå­—æ®µ
            for table in parsed.get('tables', []):
                if table.get('page') not in page_nums:
                    print(f"  âš ï¸  è¡¨æ ¼ {table.get('id')} çš„page={table.get('page')}ä¸åœ¨é¢„æœŸé¡µç ä¸­")

            for formula in parsed.get('formulas', []):
                if formula.get('page') not in page_nums:
                    print(f"  âš ï¸  å…¬å¼ {formula.get('id')} çš„page={formula.get('page')}ä¸åœ¨é¢„æœŸé¡µç ä¸­")

            for image in parsed.get('images', []):
                if image.get('page') not in page_nums:
                    print(f"  âš ï¸  å›¾ç‰‡ {image.get('id')} çš„page={image.get('page')}ä¸åœ¨é¢„æœŸé¡µç ä¸­")

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ  per_page_results å­—æ®µ
            return {
                'per_page_results': pages_data,  # æ·»åŠ è¿™ä¸€è¡Œ
                'tables': parsed.get('tables', []),
                'formulas': parsed.get('formulas', []),
                'images': parsed.get('images', [])
            }

        except json.JSONDecodeError as e:
            print(f"âš ï¸  JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å†…å®¹å‰200å­—ç¬¦: {content[:200]}...")

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡å‹æ‹’ç»æå–çš„å›å¤
            refusal_keywords = ["unable to", "cannot", "can't", "sorry", "i'm not able"]
            if any(keyword in content.lower() for keyword in refusal_keywords):
                print(f"âš ï¸  æ¨¡å‹æ‹’ç»æå–å†…å®¹ï¼Œé¡µé¢ {page_nums} å°†æ ‡è®°ä¸ºå¤„ç†å¤±è´¥")
                return {
                    "per_page_results": [{  # ä¿®æ”¹è¿™é‡Œ
                        "page_num": num,
                        "markdown": f"## ç¬¬{num}é¡µ\n**æå–å¤±è´¥ï¼šæ¨¡å‹æ‹’ç»å¤„ç†æ­¤é¡µé¢**\n{content[:500]}",
                        "page_title": f"ç¬¬{num}é¡µï¼ˆæå–å¤±è´¥ï¼‰"
                    } for num in page_nums],
                    "tables": [],
                    "formulas": [],
                    "images": []
                }

            # å¦‚æœä¸æ˜¯æ‹’ç»ï¼Œå°è¯•å°†åŸå§‹å†…å®¹ä½œä¸ºmarkdown
            print(f"âš ï¸  å°†åŸå§‹å“åº”ä½œä¸ºmarkdownå†…å®¹ä¿å­˜")
            return {
                "per_page_results": [{  # ä¿®æ”¹è¿™é‡Œ
                    "page_num": num,
                    "markdown": f"## ç¬¬{num}é¡µ\n{content}",
                    "page_title": f"ç¬¬{num}é¡µ"
                } for num in page_nums],
                "tables": [],
                "formulas": [],
                "images": []
            }

    async def call_multimodal_api(
            self,
            image_base64_list: List[str],
            page_nums: List[int],
            total_pages: int
    ) -> Dict[str, Any]:
        """è°ƒç”¨å¤šæ¨¡æ€APIçš„ç»Ÿä¸€å…¥å£ - æ ¹æ®APIç±»å‹è·¯ç”±"""
        if self.api_type == "openai_sdk":
            return await self.call_multimodal_api_openai_sdk(
                image_base64_list, page_nums, total_pages
            )
        elif self.api_type == "qwen":
            return await self.call_multimodal_api_qwen(
                image_base64_list, page_nums, total_pages
            )
        elif self.api_type == "claude":
            return await self.call_multimodal_api_claude(
                image_base64_list, page_nums, total_pages
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„APIç±»å‹: {self.api_type}")

    async def extract_from_pdf(self, pdf_path: str, original_filename: Optional[str] = None) -> ExtractionResult:
        """ä»PDFæ–‡ä»¶ä¸­æå–å®Œæ•´ä¿¡æ¯"""
        import time
        overall_start = time.time()

        # ä¼˜å…ˆä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œå¦åˆ™ä»è·¯å¾„æå–
        filename = original_filename or Path(pdf_path).name
        print(f"filename: {filename}")

        print(f"å¼€å§‹å¤„ç†PDF: {pdf_path}")
        print("=" * 60)

        # PDFè½¬å›¾ç‰‡
        convert_start = time.time()
        images = self.pdf_to_images(pdf_path)
        self.pdf_convert_time = time.time() - convert_start
        total_pages = len(images)
        print(f"âœ“ PDFè½¬æ¢å®Œæˆ: {total_pages} é¡µ (è€—æ—¶: {self.pdf_convert_time:.2f}ç§’)")

        # æ‰¹é‡å¤„ç†é¡µé¢
        per_page_results = []
        all_tables = []
        all_formulas = []

        for i in range(0, total_pages, self.pages_per_request):
            batch_images = images[i:i + self.pages_per_request]
            batch_page_nums = list(range(i + 1, min(i + 1 + self.pages_per_request, total_pages + 1)))

            image_base64_list = [self.image_to_base64(img) for img in batch_images]

            result = await self.call_multimodal_api(
                image_base64_list=image_base64_list,
                page_nums=batch_page_nums,
                total_pages=total_pages
            )

            per_page_results.extend(result['per_page_results'])
            all_tables.extend(result.get('tables', []))
            all_formulas.extend(result.get('formulas', []))

        # ç»„è£…æœ€ç»ˆmarkdown
        final_markdown = ""
        for page_result in per_page_results:
            final_markdown += page_result.get('markdown', '') + "\n\n"

        # ç»Ÿè®¡ä¿¡æ¯
        metadata = {
            "total_pages": total_pages,
            "total_tables": len(all_tables),
            "total_formulas": len(all_formulas),
            "model": self.model_name
        }

        token_usage = {
            "prompt_tokens": self.total_prompt_tokens,
            "completion_tokens": self.total_completion_tokens,
            "total_tokens": self.total_tokens
        }

        self.total_time = time.time() - overall_start
        time_cost = {
            "pdf_convert_time": round(self.pdf_convert_time, 2),
            "api_call_time": round(self.api_call_time, 2),
            "total_time": round(self.total_time, 2)
        }

        print("\n" + "=" * 60)
        print("âœ“ æå–å®Œæˆ")
        print(f"  æ€»é¡µæ•°: {total_pages}")
        print(f"  è¡¨æ ¼æ•°: {len(all_tables)}")
        print(f"  å…¬å¼æ•°: {len(all_formulas)}")
        print(
            f"  Tokenä½¿ç”¨: {self.total_tokens:,} (æç¤º: {self.total_prompt_tokens:,}, å®Œæˆ: {self.total_completion_tokens:,})")
        print(
            f"  è€—æ—¶: PDFè½¬æ¢ {self.pdf_convert_time:.2f}s + APIè°ƒç”¨ {self.api_call_time:.2f}s = æ€»è®¡ {self.total_time:.2f}s")
        print("=" * 60 + "\n")

        return ExtractionResult(
            filename=filename,
            markdown_content=final_markdown,
            tables=all_tables,
            formulas=all_formulas,
            metadata=metadata,
            token_usage=token_usage,
            time_cost=time_cost,
            page_images=images,
            per_page_results=per_page_results
        )

    def save_results(self, result: ExtractionResult, output_dir: str = "output"):
        """ä¿å­˜æå–ç»“æœåˆ°æ–‡ä»¶"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        # åˆ›å»ºimageså­ç›®å½•
        images_path = output_path / "images"
        images_path.mkdir(exist_ok=True)

        # 1. ä¿å­˜æ¯é¡µå›¾ç‰‡
        print(f"\nğŸ’¾ ä¿å­˜é¡µé¢å›¾ç‰‡...")
        for idx, image in enumerate(result.page_images):
            page_num = idx + 1
            image_filename = f"page_{page_num:03d}.jpg"
            image_path = images_path / image_filename

            # è½¬æ¢å¹¶ä¿å­˜å›¾ç‰‡
            if image.mode == 'RGBA':
                image = image.convert('RGB')
            image.save(image_path, format='JPEG', quality=95)
            print(f"  âœ“ ç¬¬{page_num}é¡µå›¾ç‰‡: {image_filename}")

        # 2. ä¿å­˜æ¯é¡µè¯†åˆ«ç»“æœ
        print(f"\nğŸ’¾ ä¿å­˜æ¯é¡µè¯†åˆ«ç»“æœ...")
        # ä¸ºæ¯é¡µç»“æœæ·»åŠ å›¾ç‰‡æ–‡ä»¶å
        for page_result in result.per_page_results:
            page_num = page_result['page_num']
            page_result['image_file'] = f"images/page_{page_num:03d}.jpg"

        with open(output_path / "per_page_results.json", 'w', encoding='utf-8') as f:
            json.dump(result.per_page_results, f, ensure_ascii=False, indent=2)
        print(f"  âœ“ æ¯é¡µç»“æœ: per_page_results.json")

        # 3. ä¿å­˜å®Œæ•´markdown
        with open(output_path / "full_content.md", 'w', encoding='utf-8') as f:
            f.write(result.markdown_content)
        print(f"  âœ“ å®Œæ•´å†…å®¹: full_content.md")

        # 4. ä¿å­˜æ‰€æœ‰è¡¨æ ¼
        with open(output_path / "tables.json", 'w', encoding='utf-8') as f:
            json.dump(result.tables, f, ensure_ascii=False, indent=2)
        print(f"  âœ“ æ‰€æœ‰è¡¨æ ¼: tables.json")

        # 5. ä¿å­˜æ‰€æœ‰å…¬å¼
        with open(output_path / "formulas.json", 'w', encoding='utf-8') as f:
            json.dump(result.formulas, f, ensure_ascii=False, indent=2)
        print(f"  âœ“ æ‰€æœ‰å…¬å¼: formulas.json")

        # 6. ä¿å­˜å…ƒæ•°æ®
        complete_metadata = {
            **result.metadata,
            "token_usage": result.token_usage,
            "time_cost": result.time_cost
        }
        with open(output_path / "metadata.json", 'w', encoding='utf-8') as f:
            json.dump(complete_metadata, f, ensure_ascii=False, indent=2)
        print(f"  âœ“ å…ƒæ•°æ®: metadata.json")

        print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_path.absolute()}")
        print(f"   - é¡µé¢å›¾ç‰‡: {len(result.page_images)} å¼ ")
        print(f"   - è¯†åˆ«ç»“æœ: {len(result.per_page_results)} é¡µ")


async def main(pdf_file, output_dir="output"):
    extractor = PDFMultimodalExtractor(
        model_url=MODEL_URL,
        api_key=API_KEY,
        model_name=MODEL_NAME
    )

    result = await extractor.extract_from_pdf(pdf_file)
    extractor.save_results(result, output_dir=output_dir)

    print("\nğŸ“ å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦):")
    print(result.markdown_content[:500])
    print("...")


if __name__ == "__main__":
    pdf_file = "D:\Pycharm_project\my_multimodal_RAG\é¥æ„Ÿæ£€æµ‹æŠ€æœ¯æ–‡æ¡£.pdf"
    output = "D:\Pycharm_project\my_multimodal_RAG\\backend\\tools"
    asyncio.run(main(pdf_file=pdf_file, output_dir=output))
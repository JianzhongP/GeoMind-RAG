
import datetime
import json
import os
import time
import uuid
from pathlib import Path
from typing import Dict, Any, Optional, List

import uvicorn
from fastapi import UploadFile, Request, HTTPException, FastAPI, File
from fastapi.responses import FileResponse

from dotenv import load_dotenv
from langchain_openai import OpenAI
from pydantic import BaseModel
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.middleware.cors import CORSMiddleware

from backend.modal_analyzer.vlm_analyzer import SimpleVLMAnalyzer, ImageType
from backend.tools.PDF_Extraction import PDFExtractionService

from embedding_model.qwen_embedding import QWENEmbedding
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document

from logger.logger import log_request
load_dotenv(override=True)

-----------é…ç½®æ—¥å¿—è®°å½•-----------
import logging
import sys
import io
# emoji æˆ–ç‰¹æ®Šç¬¦å·æ­£å¸¸æ˜¾ç¤º
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
# è®¾ç½®æ—¥å¿—çš„è·¯å¾„
log_dir = Path(.logs)
log_dir.mkdir(parents=True, exist_ok=True)
log_files = log_dir  multimodal_rag.log # è¿™é‡Œé‡è½½äº†''è¿ç®—ç¬¦ï¼Œæˆä¸ºäº†è¿æ¥ç¬¦
# åˆ›å»ºæ—¥å¿—å¯¹è±¡
logger = logging.getLogger()
logger.setLevel(logging.INFO)
# å®šä¹‰æ—¥å¿—è¾“å‡ºæ ¼å¼
formatter = logging.Formatter(
    fmt=%(asctime)s - %(name)s - %(levelname)s - %(message)s,
    datefmt=%Y-%m-%d %H%M%S,
)
# è®¾ç½®æ§åˆ¶å°è¾“å‡º
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
# è¾“å‡ºåˆ°æ–‡ä»¶
file_handler = logging.FileHandler(log_files)
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(formatter)
# å°†ä¸¤ä¸ªhandleråŠ å…¥logger
logger.addHandler(console_handler)
logger.addHandler(file_handler)

--------------------å®šä¹‰APIæ¥å£çš„æ•°æ®ç®¡ç†ç±»--------------------
class VLMModel
    è§†è§‰æ¨¡å‹ç®¡ç†
    GPT_4O = gpt-4o
    QWEN_VL = qwen-vl
    INTERN_VL = intern-vl

class RetrievalStrategy
    æ£€ç´¢ç­–ç•¥ç®¡ç†
    VECTOR = vector # å‘é‡æ£€ç´¢
    HYBRID = hybrid # æ··åˆæ£€ç´¢ï¼ˆå‘é‡+å…³é”®å­—ï¼‰
    TWO_STAGE = two-stage # ä¸¤é˜¶æ®µæ£€ç´¢ï¼ˆå…ˆç²—æ¡å†ç²¾æ’ï¼‰

class SearchRequest(BaseModel)
    æœç´¢è¯·æ±‚
    query str
    model str = VLMModel.QWEN_VL
    strategy str = RetrievalStrategy.HYBRID
    topK int = 10
    minSimilarity float = 0.0  # æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œé»˜è®¤0.0ï¼ˆä¸è¿‡æ»¤ï¼‰
    filters Optional[Dict[str, Any]] = None

class SearchResult(BaseModel)
    æœç´¢ç»“æœ
    id str
    fileName str
    filePath str
    fileType str
    similarity float
    page Optional[str] = None
    date str
    snippet str
    citationNumber int
    thumbnailType str
    thumbnailUrl Optional[str] = None
    previewUrl Optional[str] = None
    version str
    structuredData List[Dict[str, str]]

class SearchResponse(BaseModel)
    æœç´¢å“åº”
    results List[SearchResult]
    totalCount int
    queryTime float
    model str
    strategy str

class UploadResponse(BaseModel)
    ä¸Šä¼ å“åº”
    success bool
    fileId str
    fileName str
    message Optional[str] = None
    detectedImageType Optional[str] = None  # æ£€æµ‹åˆ°çš„å›¾ç‰‡ç±»å‹

class FollowUpQuestionRequest(BaseModel)
    è¿½é—®è¯·æ±‚
    documentId str
    question str
    model str = VLMModel.GPT_4O

class FollowUpQuestionResponse(BaseModel)
    è¿½é—®å“åº”
    answer str
    citations List[int]
    confidence float

class IntelligentQARequest(BaseModel)
    æ™ºèƒ½é—®ç­”è¯·æ±‚
    question str
    filters Optional[Dict[str, Any]] = None  # å¯é€‰çš„è¿‡æ»¤æ¡ä»¶
    top_k int = 3

class IntelligentQAResponse(BaseModel)
    æ™ºèƒ½é—®ç­”å“åº”
    answer str
    sources List[Dict[str, Any]]
    confidence float
    query_type str  # exact_query, filter_query, general_query

----------------å‘é‡æ•°æ®åº“ç®¡ç†å™¨------------------
class VectorStoreManager
    ä½¿ç”¨ Chroma DB 

    def __init__(self, db_path str =.chroma_db)
        self.db_path = db_path
        os.makedirs(self.db_path, exist_ok=True)

        # æ ¹æ®æ‰€é€‰ åµŒå…¥æ¨¡å‹ åˆå§‹åŒ–
        logger.info(åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ ...)
        self.embeddingm_type = os.getenv(EMBEDDING_QWEN, EMBEDDING_HF)

        # åˆ¤æ–­åµŒå…¥æ¨¡å‹çš„ç±»å‹
        if self.embeddingm_type == qwen
            logger.info(ä½¿ç”¨çš„æ˜¯ é€šä¹‰åƒé—® å¤§æ¨¡å‹ï¼š)
            self.embeddings_model = QWENEmbedding(
                model=os.getenv(QWEN_EMBEDDING_MODEL_NAME),
                api_key=os.getenv(QWEN_API_KEY),
                base_url=os.getenv(QWEN_BASE_URL),
                dimensions=int(os.getenv(QWEN_DIMENSIONS, 1024)),
            )
        else
            # ä½¿ç”¨ HuggingFace Embeddingï¼ˆé»˜è®¤ï¼Œç¦»çº¿å¯ç”¨ï¼‰
            print(  ä½¿ç”¨ HuggingFace Embedding)
            model_name = os.getenv(EMBEDDING_MODEL, sentence-transformersparaphrase-multilingual-MiniLM-L12-v2)
            self.embeddings_model = HuggingFaceEmbeddings(
                model_name=model_name,
                model_kwargs={'device' 'cpu'},
                encode_kwargs={'normalize_embeddings' True}
            )

        # åˆå§‹åŒ– chorma db æ•°æ®åº“
        self.vector_store = Chroma(
            persist_directory=self.db_path,
            embedding_function=self.embeddings_model,
            collection_name=multimodalRAG
        )

        # åˆ›å»ºæ–‡æœ¬åˆ†å‰²å™¨ï¼Œçº¦å®šå‡ ä¸ªå‚æ•°
        chunk_size = int(os.getenv(CHUNK_SIZE, 512))
        chunk_overlap = int(os.getenv(CHUNK_OVERLAP, 128))
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separators=[nn, n, ã€‚, ï¼, ï¼Ÿ, ï¼›, ï¼Œ,  , ]
        )

        # è®°å½•æ—¥å¿—
        logger.info(f  å‘é‡æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ)
        logger.info(f  Embeddingç±»å‹ {self.embeddingm_type})
        logger.info(f  åˆ†å—å¤§å° {chunk_size}, é‡å  {chunk_overlap})

    async def add_document(self,
                           file_type str,
                           file_name str,
                           file_id str,
                           content str,
                           metadata Dict[str, Any],) - int
        æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“
        print(fnğŸ“¥ æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“ {file_name})

        # åˆ†å‰²æ–‡æœ¬
        chunks = self.splitter.split_text(content)
        logger.info(f  åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—)

        # åˆ›å»º Document å¯¹è±¡
        documents = []
        for i, chunk in enumerate(chunks)
            doc_metadata = {
                file_id file_id,
                file_name file_name,
                file_type file_type,
                chunk_id i,
                total_chunks len(chunks),
                upload_date datetime.now().isoformat(),
                metadata
            }

            documents.append(Document(
                page_content=chunk,
                metadata=doc_metadata
            ))

        # æ·»åŠ åˆ°å‘é‡åº“
        ids = [f{file_id}_chunk_{i} for i in range(len(documents))]
        self.vector_store.add_documents(documents, ids=ids)

        logger.info(fâœ“ æ–‡æ¡£å·²æ·»åŠ åˆ°å‘é‡åº“ï¼Œå…± {len(documents)} ä¸ªå—)
        return len(documents)

    async def search(
            self,
            query str,
            top_k int = 10,
            file_type_filter Optional[str] = None
    ) - List[Dict[str, Any]]
        å‘é‡æ£€ç´¢
        print(fnğŸ” æ‰§è¡Œå‘é‡æ£€ç´¢ {query[50]}...)

        # æ„å»ºè¿‡æ»¤å™¨
        where_filter = {}
        if file_type_filter
            where_filter[file_type] = file_type_filter

        # æ‰§è¡Œæ£€ç´¢
        if where_filter
            results = self.vector_store.similarity_search_with_score(
                query,
                k=top_k,
                filter=where_filter
            )
        else
            results = self.vector_store.similarity_search_with_score(
                query,
                k=top_k
            )

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for doc, score in results
            # ChromaDB ä½¿ç”¨ L2 (æ¬§å‡ é‡Œå¾—è·ç¦») æˆ–ä½™å¼¦è·ç¦»
            # L2 è·ç¦»èŒƒå›´å¯èƒ½å¾ˆå¤§ï¼Œä½™å¼¦è·ç¦»èŒƒå›´æ˜¯ [0, 2]
            #
            # æ–¹æ¡ˆ1ï¼šä½¿ç”¨å€’æ•°å½’ä¸€åŒ–ï¼ˆé€‚ç”¨äºå„ç§è·ç¦»åº¦é‡ï¼‰
            # similarity = 1  (1 + distance)
            #
            # æ–¹æ¡ˆ2ï¼šä½™å¼¦è·ç¦»è½¬ç›¸ä¼¼åº¦
            # similarity = 1 - (distance  2)
            #
            # æˆ‘ä»¬ä½¿ç”¨æ–¹æ¡ˆ1ï¼Œå› ä¸ºå®ƒå¯¹ä»»ä½•è·ç¦»éƒ½æœ‰æ•ˆ
            # æ³¨æ„ï¼Œè¿™é‡Œè¿˜å¯ä»¥æ·»åŠ ç¼©æ”¾å› å­è¿›å…¥
            similarity = 1.0  (1.0 + score)  # è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜

            formatted_results.append({
                content doc.page_content,
                metadata doc.metadata,
                similarity float(similarity),
                distance float(score)  # ä¿ç•™åŸå§‹è·ç¦»ç”¨äºè°ƒè¯•
            })

        logger.info(fâœ“ æ‰¾åˆ° {len(formatted_results)} ä¸ªç›¸å…³ç»“æœ)

        # ã€è°ƒè¯•ã€‘æ˜¾ç¤ºè·ç¦»å’Œç›¸ä¼¼åº¦çš„å¯¹åº”å…³ç³»
        if formatted_results
            logger.info(
                f  è·ç¦»èŒƒå›´ {min(r['distance'] for r in formatted_results).4f} ~ {max(r['distance'] for r in formatted_results).4f})
            logger.info(
                f  ç›¸ä¼¼åº¦èŒƒå›´ {min(r['similarity'] for r in formatted_results).4f} ~ {max(r['similarity'] for r in formatted_results).4f})

        return formatted_results


-------------åˆå§‹åŒ–ä¸»ç¨‹åºç±»---------------
class MultiModalRAGService
    def __init__(self, )
        # é…ç½®æ¨¡å‹å‚æ•°
        self.model_url = os.getenv(QWEN_BASE_URL)
        self.infermodel_api_key = os.getenv('QWEN_API_KEY')
        self.embeddingmodel_name = os.getenv('QWEN_EMBEDDING_MODEL_NAME')
        self.infermodel_name = os.getenv('QWEN_EMBEDDING_MODEL_NAME')

        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.pdf_service = PDFExtractionService()
        self.vector_manager = VectorStoreManager()

        # åˆå§‹åŒ–è°ƒç”¨çš„æ¨¡å‹
        self.vlm_analyzer = SimpleVLMAnalyzer(
            model_url= self.model_url,
            api_key=self.infermodel_api_key,
            model_name=self.infermodel_name,
        )
        # è®¾ç½®æ–‡ä»¶å­˜å‚¨ç›®å½•
        self.load_dir = Path(.files_load)
        self.load_dir.mkdir(parents=True, exist_ok=True)

        # é¢„è§ˆå›¾å­˜å‚¨åœ°å€
        self.preview_dir = Path(.preview)
        self.preview_dir.mkdir(parents=True, exist_ok=True)

        print(æœåŠ¡ç«¯åˆå§‹åŒ–å®Œæˆ)
        print('n'+'-'50)

    def _format_extracted_info_to_natural_language(self, info Dict[str, Any], image_type=None) - str
        å°†ç»“æ„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€
        if not info
            return 

        lines = []

        # åŸºæœ¬å…ƒä¿¡æ¯
        if drawing_title in info
            lines.append(få›¾çº¸åç§°ï¼š{info['drawing_title']})
        if source in info
            lines.append(fæ•°æ®æºï¼š{info['source']})
        if acquisition_date in info
            lines.append(fé‡‡é›†æ—¶é—´ï¼š{info['acquisition_date']})
        if crs in info
            lines.append(fæŠ•å½±åæ ‡ç³»ï¼š{info['crs']})
        if resolution_m in info
            lines.append(fåˆ†è¾¨ç‡ï¼š{info['resolution_m']} ç±³åƒå…ƒ)

        # ä¸åŒå›¾åƒç±»å‹çš„ç‰¹å®šä¿¡æ¯ç»„è£…
        if image_type == ImageType.Classification
            # åˆ†ç±»å›¾ä¿¡æ¯
            if area_stats_km2 in info
                area_lines = []
                for cls, stats in info[area_stats_km2].items()
                    area_lines.append(
                        f- {cls}ï¼šåƒå…ƒæ•° {stats.get('pixel_count', 0)}ï¼Œé¢ç§¯ {stats.get('area_km2', 0).2f} kmÂ²
                    )
                lines.append(nç±»åˆ«é¢ç§¯ç»Ÿè®¡ï¼šn + n.join(area_lines))

            if spatial_summary in info
                lines.append(nç©ºé—´åˆ†å¸ƒæ‘˜è¦ï¼š)
                for item in info[spatial_summary]
                    lines.append(
                        f- {item.get('class')} ç±»ä¸»è¦é›†ä¸­åœ¨ {', '.join(item.get('major_clusters', []))}ï¼Œ
                        fè´¨å¿ƒç»çº¬åº¦ ({item.get('centroid_lon')}, {item.get('centroid_lat')})
                    )

            if notable_findings in info
                lines.append(næ˜¾è‘—å‘ç°ï¼š)
                for finding in info[notable_findings]
                    lines.append(f- {finding})

        elif image_type == ImageType.Detection
            if detections in info
                lines.append(næ£€æµ‹ç›®æ ‡æ¸…å•ï¼š)
                for det in info[detections]
                    lines.append(
                        f- ID {det['id']}ï¼šç±»åˆ« {det['class']}ï¼Œç½®ä¿¡åº¦ {det['confidence'].2f}ï¼Œ
                        fé¢ç§¯ {det.get('area_m2', 0).1f} mÂ²ï¼Œè´¨å¿ƒ {det.get('centroid_lonlat', 'NA')}
                    )

            if changes in info
                lines.append(nå˜åŒ–æ£€æµ‹ï¼š)
                for chg in info[changes]
                    lines.append(
                        f- {chg['type']} ç±»åˆ« {chg['class']}ï¼Œå˜åŒ–ç‡ {chg.get('area_change_pct', 0).1f}%ï¼Œ
                        fä½ç½® {chg.get('location', 'æœªçŸ¥')}
                    )

        elif image_type == ImageType.Technology_map
            if modules in info
                lines.append(næ¨¡å—ç»„æˆï¼š)
                for m in info[modules]
                    lines.append(f- {m['name']}ï¼š{m['description']})

            if flow_sequence in info
                lines.append(næµç¨‹æ­¥éª¤ï¼š)
                for step in info[flow_sequence]
                    lines.append(fæ­¥éª¤ {step['step']}ï¼š{step['module']} â†’ {', '.join(step.get('next', []))})

            if potential_bottlenecks in info
                lines.append(næ½œåœ¨ç“¶é¢ˆï¼š)
                lines.extend([-  + b for b in info[potential_bottlenecks]])

        elif image_type == ImageType.Technical_doc
            if meta in info
                meta = info[meta]
                lines.append(
                    fæ–‡æ¡£ã€Š{meta.get('title', 'æœªå‘½å')}ã€‹ï¼Œç‰ˆæœ¬ {meta.get('version', 'æœªçŸ¥')}ï¼Œ
                    fä½œè€… {meta.get('author', 'æœªçŸ¥')}ï¼Œé¡µæ•° {meta.get('pages', '')}
                )

            if chapters in info
                lines.append(nç« èŠ‚æ‘˜è¦ï¼š)
                for ch in info[chapters]
                    lines.append(f- {ch['chapter']}ï¼š{ch['summary']})

            if technical_parameters in info
                lines.append(nå…³é”®å‚æ•°ï¼š)
                for p in info[technical_parameters]
                    lines.append(f- {p['name']} = {p['value']} {p['unit']}ï¼ˆç¬¬ {p['page']} é¡µï¼‰)

        return n.join(lines)

    async def _detect_image_type(
            self,
            image_path Path,
            user_specified_type Optional[str] = None
    ) - str
        
        æ™ºèƒ½æ£€æµ‹å›¾ç‰‡ç±»å‹

        Args
            image_path å›¾ç‰‡è·¯å¾„
            user_specified_type ç”¨æˆ·æŒ‡å®šçš„ç±»å‹ï¼ˆå¦‚æœæœ‰ï¼‰

        Returns
            ImageType æšä¸¾å€¼
        
        # å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
        if user_specified_type
            logger.info(f  ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å›¾ç‰‡ç±»å‹ {user_specified_type})
            return user_specified_type

        logger.info(fğŸ” æ™ºèƒ½æ£€æµ‹å›¾ç‰‡ç±»å‹...)

        # ä½¿ç”¨ VLM è¿›è¡Œæ™ºèƒ½è¯†åˆ«
        try
            # ç»™VLMæ™ºèƒ½æ£€æµ‹çš„æç¤ºè¯
            detection_prompt = 
            è¯·å¿«é€Ÿè¯†åˆ«è¿™å¼ å›¾ç‰‡çš„ç±»å‹ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªï¼š

            1. classification - é¥æ„Ÿåˆ†ç±»å›¾åƒï¼ˆåŒ…å«åˆ†ç±»ç›®æ ‡ã€åˆ†å¸ƒæƒ…å†µï¼‰
            2. detection - ç›®æ ‡æ£€æµ‹å›¾ï¼ˆåŒ…å«ç›®æ ‡æ¡†ã€ç›®æ ‡ç±»åˆ«ï¼‰
            3. technology_map - ç³»ç»Ÿæ¶æ„å›¾ï¼ˆåŒ…å«æ¨¡å—ã€ç»„ä»¶ã€æ•°æ®æµï¼‰
            4. technical_doc - å·¥ä¸šæŠ€æœ¯æ¡£æ¡ˆæ–‡ä»¶ï¼ˆåŒ…å«è¡¨æ ¼ã€å‚æ•°ã€è¦æ±‚ï¼‰
            
            åˆ¤æ–­ä¾æ®ï¼š
            - å¦‚æœæœ‰å¤§é‡åˆ†ç±»åƒç´ ç‚¹ã€åˆ†ç±»ç±»åˆ«ã€é¥æ„Ÿå›¾åƒ â†’ classification
            - å¦‚æœæœ‰ç›®æ ‡æ¡†ã€ç±»åˆ«ä¿¡æ¯ã€é¥æ„Ÿå›¾åƒ â†’ detection
            - å¦‚æœæœ‰æµç¨‹å›¾ã€æ¶æ„å›¾ã€ç»„ä»¶å…³ç³»ã€ç®­å¤´è¿æ¥ â†’ technology_map
            - å¦‚æœæœ‰è¡¨æ ¼ã€åŸºæœ¬æµç¨‹ã€é‡åŒ–æŒ‡æ ‡ â†’ technical_doc
            
            è¯·ç›´æ¥è¿”å›ç±»å‹åç§°ï¼ˆå°å†™ï¼‰ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚
            

            # ä½¿ç”¨è¾ƒå°çš„ token é™åˆ¶å¿«é€Ÿåˆ¤æ–­
            from PIL import Image
            image = Image.open(image_path)
            image_base64 = self.vlm_analyzer.image_to_base64(image, max_size=1000)

            # è°ƒç”¨ VLM API
            messages = [
                {
                    role user,
                    content [
                        {
                            type image_url,
                            image_url {
                                url fdataimagejpeg;base64,{image_base64}
                            }
                        },
                        {
                            type text,
                            text detection_prompt
                        }
                    ]
                }
            ]

            response = await self.vlm_analyzer.openai_client.chat.completions.create(
                model=self.infermodel_name,
                messages=messages,
                max_tokens=50,
                temperature=0.0
            )

            detected_type = response.choices[0].message.content.strip().lower()

            # éªŒè¯è¿”å›çš„ç±»å‹
            valid_types = [ImageType.Classification, ImageType.Detection, ImageType.Technology_map, ImageType.Technical_doc]
            if detected_type in valid_types
                logger.info(f  âœ“ æ™ºèƒ½è¯†åˆ«ç»“æœ {detected_type})
                return detected_type
            else
                logger.warning(f  âš ï¸ æ— æ³•è¯†åˆ«ç±»å‹ {detected_type}ï¼Œä½¿ç”¨é»˜è®¤ç±»å‹ technology_map)
                return ImageType.Technology_map

        except Exception as e
            logger.warning(f  âš ï¸ æ™ºèƒ½è¯†åˆ«å¤±è´¥ {e}ï¼Œä½¿ç”¨é»˜è®¤ç±»å‹ technology_map)
            return ImageType.Technology_map

    def _generate_pdf_thumbnail(self, pdf_path Path, file_id str) - Path
        ç”ŸæˆPDFé¦–é¡µç¼©ç•¥å›¾
        import fitz # PDF å¤„ç†åº“
        from PIL import Image
        import io

        try
            # æ‰“å¼€PDF
            doc = fitz.open(str(pdf_path))

            # è·å–ç¬¬ä¸€é¡µ
            page = doc[0]

            # æ¸²æŸ“ä¸ºå›¾åƒï¼ˆæé«˜åˆ†è¾¨ç‡ä»¥è·å¾—æ›´æ¸…æ™°çš„ç¼©ç•¥å›¾ï¼‰
            mat = fitz.Matrix(2.0, 2.0)  # 2å€ç¼©æ”¾
            pix = page.get_pixmap(matrix=mat)

            # è½¬æ¢ä¸ºPIL Image
            img_data = pix.tobytes(png)
            img = Image.open(io.BytesIO(img_data))

            # åˆ›å»ºç¼©ç•¥å›¾ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
            img.thumbnail((400, 400), Image.Resampling.LANCZOS)

            # ä¿å­˜ç¼©ç•¥å›¾
            thumbnail_path = self.preview_dir  f{file_id}_thumb.png
            img.save(thumbnail_path, PNG, optimize=True)

            doc.close()

            logger.info(fâœ“ PDFç¼©ç•¥å›¾å·²ç”Ÿæˆ {thumbnail_path})
            return thumbnail_path

        except Exception as e
            logger.error(fç”ŸæˆPDFç¼©ç•¥å›¾å¤±è´¥ {e})
            return None

    async def _analyze_pdf_images(
            self,
            pdf_path Path,
            extraction_result Dict[str, Any]
    ) - str
        
        åˆ†æPDFä¸­çš„å›¾ç‰‡é¡µé¢ï¼Œä½¿ç”¨VLMæå–ä¿¡æ¯

        Args
            pdf_path PDFæ–‡ä»¶è·¯å¾„
            extraction_result PDFæå–ç»“æœ

        Returns
            å›¾ç‰‡åˆ†æçš„æ–‡æœ¬å†…å®¹
        
        import fitz
        from PIL import Image
        import io

        logger.info(  å¼€å§‹åˆ†æPDFä¸­çš„å›¾ç‰‡é¡µé¢...)

        image_analysis_results = []

        try
            doc = fitz.open(str(pdf_path))

            # éå†æ¯ä¸€é¡µ
            for page_num in range(len(doc))
                page = doc[page_num]

                # è·å–é¡µé¢å›¾ç‰‡
                image_list = page.get_images(full=True)

                # å¦‚æœè¿™ä¸€é¡µæœ‰å›¾ç‰‡ï¼Œæˆ–è€…è¿™ä¸€é¡µä¸»è¦æ˜¯å›¾ç‰‡ï¼ˆæ–‡æœ¬å¾ˆå°‘ï¼‰
                text_length = len(page.get_text().strip())

                # åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡é¡µï¼šæœ‰å›¾ç‰‡ä¸”æ–‡æœ¬å°‘äº100å­—ç¬¦
                if image_list and text_length  100
                    logger.info(f  å‘ç°å›¾ç‰‡é¡µ ç¬¬ {page_num + 1} é¡µ)

                    # æ¸²æŸ“æ•´é¡µä¸ºå›¾ç‰‡
                    mat = fitz.Matrix(2.0, 2.0)  # 2å€ç¼©æ”¾
                    pix = page.get_pixmap(matrix=mat)

                    # è½¬æ¢ä¸ºPIL Image
                    img_data = pix.tobytes(png)
                    image = Image.open(io.BytesIO(img_data))

                    # æ™ºèƒ½æ£€æµ‹å›¾ç‰‡ç±»å‹
                    # å…ˆä¿å­˜ä¸´æ—¶æ–‡ä»¶ç”¨äºæ£€æµ‹
                    temp_path = self.load_dir  ftemp_page_{page_num}.png
                    image.save(temp_path, PNG)

                    detected_type = await self._detect_image_type(temp_path)

                    # ä½¿ç”¨ VLM åˆ†æ
                    analysis_result = await self.vlm_analyzer.analyze_image(
                        image,
                        question=fè¿™æ˜¯PDFæ–‡æ¡£ç¬¬{page_num + 1}é¡µçš„å†…å®¹ï¼Œè¯·è¯¦ç»†æè¿°è¿™å¼ å›¾çš„æ‰€æœ‰ä¿¡æ¯ã€‚,
                        image_type=detected_type
                    )

                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if temp_path.exists()
                        temp_path.unlink()

                    # ä¿å­˜åˆ†æç»“æœ
                    image_analysis_results.append({
                        'page' page_num + 1,
                        'type' detected_type,
                        'analysis' analysis_result.answer,
                        'structured_info' analysis_result.extracted_info
                    })

                    logger.info(f  âœ“ ç¬¬ {page_num + 1} é¡µåˆ†æå®Œæˆ (ç±»å‹ {detected_type}))

            doc.close()

            # æ ¼å¼åŒ–å›¾ç‰‡åˆ†æç»“æœ
            if image_analysis_results
                formatted_results = nn=== PDFå›¾ç‰‡é¡µé¢åˆ†æ ===nn
                for result in image_analysis_results
                    formatted_results += fã€ç¬¬{result['page']}é¡µ - {result['type']}ã€‘n
                    formatted_results += f{result['analysis']}n
                    if result['structured_info']
                        formatted_results += fç»“æ„åŒ–ä¿¡æ¯ {result['structured_info']}n
                    formatted_results += n

                logger.info(fâœ“ PDFå›¾ç‰‡åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(image_analysis_results)} é¡µ)
                return formatted_results
            else
                logger.info(  æœªå‘ç°éœ€è¦VLMåˆ†æçš„å›¾ç‰‡é¡µé¢)
                return 

        except Exception as e
            logger.error(f  PDFå›¾ç‰‡åˆ†æå¤±è´¥ {e})
            import traceback
            traceback.print_exc()
            return 

    async def handle_search(
            self,
            request SearchRequest
    ) - SearchResponse
        å¤„ç†æœç´¢è¯·æ±‚
        import time
        start_time = time.time()

        logger.info(fn{'='  60})
        logger.info(f  å¤„ç†æœç´¢è¯·æ±‚)
        logger.info(f  æŸ¥è¯¢ {request.query})
        logger.info(f  æ¨¡å‹ {request.model})
        logger.info(f  ç­–ç•¥ {request.strategy})
        logger.info(f  TopK {request.topK})
        logger.info(f  æœ€å°ç›¸ä¼¼åº¦ {request.minSimilarity})
        logger.info(f{'='  60})

        # æ‰§è¡Œå‘é‡æ£€ç´¢ - æ£€ç´¢æ›´å¤šchunkä»¥ä¾¿èšåˆ
        vector_results = await self.vector_manager.search(
            query=request.query,
            top_k=request.topK  3  # æ£€ç´¢3å€æ•°é‡ï¼Œç”¨äºèšåˆåç­›é€‰
        )

        # å¦‚æœæ²¡æœ‰åœ¨æœ¬åœ°å‘é‡æ•°æ®åº“æ£€ç´¢åˆ°ä»»ä½•å†…å®¹
        if not vector_results
            print(hhhhhhhhhhhhhhhhhhh)
            from openai import OpenAI
            client = OpenAI(
                api_key=os.getenv(QWEN_API_KEY),
                base_url=os.getenv(QWEN_BASE_URL),
            )
            res = client.chat.completions.create(
                model=os.getenv(QWEN_MULTIMODAL_MODAL_NAME),
                messages=[
                    {role system,
                     content ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¥æ„Ÿé¢†åŸŸçŸ¥è¯†ä¸äº¤å·®å­¦ç§‘ä¸“å®¶ï¼Œç°åœ¨ç§æœ‰æ•°æ®åº“ä¸­æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³ä¿¡æ¯ï¼Œå…ˆå’Œç”¨æˆ·æ¾„æ¸…è¿™ä¸€ç‚¹ï¼Œç„¶åæ¥ç€æ¾„æ¸…è‡ªå·±å°†é€šè¿‡è‡ªå·±çš„ç°æœ‰çŸ¥è¯†å›ç­”é—®é¢˜},
                    {role user, content question}
                ]
            )
            return SearchResponse(
            results=res.choices[0].message.content,
            queryTime=os.times(),  # è½¬æ¢ä¸ºæ¯«ç§’
            model=request.model,
            strategy=request.strategy
        )

        # ã€æ–°å¢ã€‘æŒ‰æ–‡ä»¶èšåˆç»“æœ
        file_results = {}  # {file_id {metadata, chunks, max_similarity}}

        for result in vector_results
            metadata = result[metadata]
            file_id = metadata.get(file_id, unknown)

            if file_id not in file_results
                file_results[file_id] = {
                    metadata metadata,
                    chunks [],
                    max_similarity result[similarity]
                }

            file_results[file_id][chunks].append({
                content result[content],
                similarity result[similarity],
                chunk_id metadata.get(chunk_id, 0)
            })

            # æ›´æ–°æœ€é«˜ç›¸ä¼¼åº¦
            if result[similarity]  file_results[file_id][max_similarity]
                file_results[file_id][max_similarity] = result[similarity]

        # ã€æ–°å¢ã€‘æŒ‰æœ€é«˜ç›¸ä¼¼åº¦æ’åºæ–‡ä»¶
        sorted_files = sorted(
            file_results.items(),
            key=lambda x x[1][max_similarity],
            reverse=True
        )

        # ã€è°ƒè¯•ã€‘æ‰“å°ç›¸ä¼¼åº¦ä¿¡æ¯
        if sorted_files
            logger.info(fn  ç›¸ä¼¼åº¦åˆ†å¸ƒ)
            for i, (file_id, file_data) in enumerate(sorted_files[5], 1)  # åªæ˜¾ç¤ºå‰5ä¸ª
                logger.info(
                    f  [{i}] {file_data['metadata'].get('file_name', 'unknown')} {file_data['max_similarity'].6f})

        # ã€æ–°å¢ã€‘æ ¹æ®ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
        filtered_files = [
            (file_id, file_data)
            for file_id, file_data in sorted_files
            if file_data[max_similarity] = request.minSimilarity
        ]

        # ã€æ–°å¢ã€‘åªä¿ç•™ topK ä¸ªæ–‡ä»¶
        final_files = filtered_files[request.topK]

        logger.info(f  åŸå§‹æ£€ç´¢ {len(vector_results)} ä¸ªchunk)
        logger.info(f  èšåˆå»é‡ {len(sorted_files)} ä¸ªæ–‡ä»¶)
        logger.info(f  ç›¸ä¼¼åº¦è¿‡æ»¤(={request.minSimilarity}) {len(filtered_files)} ä¸ªæ–‡ä»¶)
        logger.info(f  æœ€ç»ˆè¿”å›(topK={request.topK}) {len(final_files)} ä¸ªæ–‡ä»¶)

        # æ ¼å¼åŒ–ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
        search_results = []
        for idx, (file_id, file_data) in enumerate(final_files)
            metadata = file_data[metadata]
            chunks = file_data[chunks]

            # ç¡®å®šæ–‡ä»¶ç±»å‹
            file_name = metadata.get(file_name, )
            image_type = metadata.get(image_type, )

            # æ ¹æ®æ£€æµ‹çš„å›¾ç‰‡ç±»å‹è®¾ç½®æ˜¾ç¤ºç±»å‹
            if image_type
                file_type_map = {
                    ImageType.Classification é¥æ„Ÿåˆ†ç±»å›¾,
                    ImageType.Detection ç›®æ ‡æ£€æµ‹å›¾,
                    ImageType.Technology_map æ¶æ„æŠ€æœ¯è·¯çº¿å›¾,
                    ImageType.Technical_doc æŠ€æœ¯æ–‡æ¡£
                }
                file_type = file_type_map.get(image_type, å›¾ç‰‡)
                thumbnail_type = image
            elif file_name.lower().endswith('.pdf')
                file_type = PDF
                thumbnail_type = pdf
            elif any(ext in file_name.lower() for ext in ['.png', '.jpg', '.jpeg'])
                file_type = å›¾ç‰‡
                thumbnail_type = image
            else
                file_type = å…¶ä»–
                thumbnail_type = image

            # ã€æ–°å¢ã€‘åˆå¹¶å¤šä¸ªchunkçš„å†…å®¹ä½œä¸ºsnippet
            # é€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„chunkä½œä¸ºä¸»è¦snippet
            best_chunk = max(chunks, key=lambda c c[similarity])
            snippet = best_chunk[content][200]

            # å¦‚æœæœ‰å¤šä¸ªchunkï¼Œæ·»åŠ æç¤º
            if len(chunks)  1
                snippet += f... (å…±{len(chunks)}ä¸ªç›¸å…³ç‰‡æ®µ)

            # æå–é¡µç ä¿¡æ¯
            page_info = metadata.get(page, NA)

            search_result = SearchResult(
                id=file_id,
                fileName=file_name,
                filePath=metadata.get(file_path, ffiles{file_id}),
                fileType=file_type,
                similarity=file_data[max_similarity],
                page=str(page_info) if page_info else None,
                date=metadata.get(upload_date, datetime.now().isoformat())[10],
                snippet=snippet,
                citationNumber=idx + 1,
                thumbnailType=thumbnail_type,
                thumbnailUrl=fapithumbnail{file_id},
                previewUrl=fapipreview{file_id},
                version=metadata.get(version, v1.0),
                structuredData=self._extract_structured_data(metadata)
            )

            search_results.append(search_result)

        query_time = time.time() - start_time

        print(fnâœ“ æœç´¢å®Œæˆ)
        logger.info(f  è¿”å› {len(search_results)} ä¸ªæ–‡æ¡£)
        logger.info(f  è€—æ—¶ {query_time.2f}ç§’)

        return SearchResponse(
            results=search_results,
            totalCount=len(search_results),
            queryTime=round(query_time  1000),  # è½¬æ¢ä¸ºæ¯«ç§’
            model=request.model,
            strategy=request.strategy
        )

    async def handle_upload(
            self,
            file UploadFile,
            image_type Optional[str] = None
    ) - UploadResponse
        
        å¤„ç†æ–‡ä»¶ä¸Šä¼ 

        Args
            file ä¸Šä¼ çš„æ–‡ä»¶
            image_type ç”¨æˆ·æŒ‡å®šçš„å›¾ç‰‡ç±»å‹ï¼ˆå¯é€‰ï¼‰
                       æ”¯æŒ cad, floor_plan, architecture, technical_doc
        
        logger.info(fn{'='  60})
        logger.info(fğŸ“¤ å¤„ç†æ–‡ä»¶ä¸Šä¼  {file.filename})
        if image_type
            logger.info(f   ç”¨æˆ·æŒ‡å®šç±»å‹ {image_type})
        logger.info(f{'='  60})

        try
            # ç”Ÿæˆæ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            file_extension = Path(file.filename).suffix.lower()

            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            file_path = self.upload_dir  f{file_id}{file_extension}
            content = await file.read()
            with open(file_path, 'wb') as f
                f.write(content)

            logger.info(fâœ“ æ–‡ä»¶å·²ä¿å­˜ {file_path})

            detected_image_type = None  # è®°å½•æ£€æµ‹åˆ°çš„å›¾ç‰‡ç±»å‹

            # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
            if file_extension == '.pdf'
                # PDF æ–‡ä»¶ï¼šä½¿ç”¨å¿«é€Ÿæ¨¡å¼æå–
                extraction_result = await self.pdf_service.extract_fast(
                    str(file_path),
                    original_filename=file.filename
                )

                content_text = extraction_result[markdown]
                file_type = PDF

                # æå–é¡µé¢ä¿¡æ¯
                page_count = extraction_result[metadata][total_pages]

                # ç”ŸæˆPDFé¦–é¡µç¼©ç•¥å›¾
                self._generate_pdf_thumbnail(file_path, file_id)

                # ã€æ–°å¢ã€‘åˆ†æPDFä¸­çš„å›¾ç‰‡é¡µé¢
                pdf_image_analysis = await self._analyze_pdf_images(file_path, extraction_result)
                if pdf_image_analysis
                    content_text += nn + pdf_image_analysis
                    logger.info(âœ“ PDFå›¾ç‰‡é¡µé¢å·²æ•´åˆåˆ°å†…å®¹ä¸­)

            elif file_extension in ['.png', '.jpg', '.jpeg']
                # ã€æ–°å¢ã€‘æ™ºèƒ½æ£€æµ‹å›¾ç‰‡ç±»å‹
                detected_image_type = await self._detect_image_type(file_path, image_type)

                # æ ¹æ®æ£€æµ‹çš„ç±»å‹ç”Ÿæˆåˆé€‚çš„é—®é¢˜
                question_map = {
                    ImageType.Classification è¯·è¯¦ç»†æè¿°è¿™å¼ åˆ†ç±»å›¾çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ‰€æœ‰å¯è§çš„åˆ†ç±»å¯¹è±¡ã€åˆ†ç±»åŒºåŸŸã€åˆ†å¸ƒæƒ…å†µç­‰ã€‚,
                    ImageType.Detection è¯·è¯¦ç»†æè¿°è¿™å¼ ç›®æ ‡æ£€æµ‹å›¾ï¼ŒåŒ…æ‹¬ç›®æ ‡æ¡†å¯¹è±¡ã€ç›®æ ‡æ¡†ä¿¡æ¯ã€ä½¿ç”¨åœºæ™¯ç­‰ä¿¡æ¯ã€‚,
                    ImageType.Technology_map è¯·è¯¦ç»†æè¿°è¿™å¼ æ¶æ„å›¾æµç¨‹å›¾ï¼ŒåŒ…æ‹¬æ‰€æœ‰ç»„ä»¶ã€æ¨¡å—ã€å…³ç³»å’Œæµç¨‹ã€‚,
                    ImageType.Technical_doc è¯·è¯¦ç»†æè¿°è¿™ä»½æŠ€æœ¯æ–‡æ¡£ï¼ŒåŒ…æ‹¬æ‰€æœ‰å¯è§çš„å‚æ•°ã€è¡¨æ ¼æ•°æ®ã€æ³¨æ„ä¿¡æ¯ç­‰ã€‚
                }

                question = question_map.get(detected_image_type, è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾çš„æ‰€æœ‰å†…å®¹ã€‚)

                # å›¾åƒæ–‡ä»¶ï¼šä½¿ç”¨ VLM åˆ†æ
                analysis_result = await self.vlm_analyzer.analyze_image(
                    str(file_path),
                    question=question,
                    image_type=detected_image_type
                )

                # ã€ä¼˜åŒ–ã€‘å°†ç»“æ„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€
                natural_language_info = self._format_extracted_info_to_natural_language(
                    analysis_result.extracted_info
                )
                content_text = f{analysis_result.answer}nn{natural_language_info}

                # ã€æ–°å¢ã€‘æ ¹æ®æ£€æµ‹ç±»å‹è®¾ç½®æ–‡ä»¶ç±»å‹
                file_type_map = {
                    ImageType.Classification é¥æ„Ÿåˆ†ç±»å›¾,
                    ImageType.Detection ç›®æ ‡æ£€æµ‹å›¾,
                    ImageType.Technology_map æ¶æ„æŠ€æœ¯è·¯çº¿å›¾,
                    ImageType.Technical_doc æŠ€æœ¯æ–‡æ¡£
                }
                file_type = file_type_map.get(detected_image_type, å›¾ç‰‡)
                page_count = 1

            else
                raise HTTPException(status_code=400, detail=fä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ {file_extension})

            # æ·»åŠ åˆ°å‘é‡åº“
            metadata = {
                file_path str(file_path),
                file_extension file_extension,
                page_count page_count,
                version v1.0
            }

            # å¦‚æœæœ‰æ£€æµ‹åˆ°çš„å›¾ç‰‡ç±»å‹ï¼Œæ·»åŠ åˆ°å…ƒæ•°æ®
            if detected_image_type
                metadata[image_type] = detected_image_type

            # # ã€æ–°å¢ã€‘å¦‚æœæœ‰åˆ†æç»“æœï¼Œå­˜å‚¨ç»“æ„åŒ–ä¿¡æ¯åˆ°å…ƒæ•°æ®
            # if 'analysis_result' in locals()
            #     # âš ï¸ ChromaDB ä¸æ”¯æŒåµŒå¥—å­—å…¸ï¼Œéœ€è¦åºåˆ—åŒ–
            #     # å°†å¤æ‚çš„ extracted_info è½¬ä¸º JSON å­—ç¬¦ä¸²
            #     metadata[extracted_info_json] = json.dumps(analysis_result.extracted_info, ensure_ascii=False)
            #
            #     # ã€æ–°å¢ã€‘æå–å…³é”®å­—æ®µåˆ°å…ƒæ•°æ®é¡¶å±‚ï¼ˆä¾¿äºè¿‡æ»¤ï¼‰
            #     extracted_info = analysis_result.extracted_info
            #     if rooms in extracted_info
            #         metadata[room_count] = len(extracted_info[rooms])
            #         # ç»Ÿè®¡å§å®¤æ•°é‡
            #         bedrooms = [r for r in extracted_info[rooms] if å§ in r.get(name, )]
            #         metadata[bedroom_count] = len(bedrooms)
            #
            #     if total_dimensions in extracted_info
            #         total_dims = extracted_info[total_dimensions]
            #         metadata[total_area] = float(total_dims.get(total_area, 0))
            #         metadata[total_length] = float(total_dims.get(length, 0))
            #         metadata[total_width] = float(total_dims.get(width, 0))

            chunk_count = await self.vector_manager.add_document(
                file_id=file_id,
                file_name=file.filename,
                file_type=file_type,
                content=content_text,
                metadata=metadata
            )

            print(fnâœ“ æ–‡ä»¶ä¸Šä¼ å¹¶ç´¢å¼•å®Œæˆ)
            logger.info(f  æ–‡ä»¶ID {file_id})
            logger.info(f  æ–‡ä»¶ç±»å‹ {file_type})
            if detected_image_type
                logger.info(f  æ£€æµ‹ç±»å‹ {detected_image_type})
            logger.info(f  åˆ†å—æ•° {chunk_count})

            return UploadResponse(
                success=True,
                fileId=file_id,
                fileName=file.filename,
                message=fæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå·²åˆ†å‰²ä¸º {chunk_count} ä¸ªæ–‡æœ¬å—å¹¶å»ºç«‹ç´¢å¼•,
                detectedImageType=detected_image_type
            )

        except Exception as e
            logger.error(fâŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥ {e})
            import traceback
            traceback.print_exc()

            return UploadResponse(
                success=False,
                fileId=,
                fileName=file.filename,
                message=fæ–‡ä»¶ä¸Šä¼ å¤±è´¥ {str(e)}
            )

    async def handle_follow_up_question(
            self,
            request FollowUpQuestionRequest
    ) - FollowUpQuestionResponse
        å¤„ç†è¿½é—®

        # æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
        results = await self.vector_manager.search(
            query=request.question,
            top_k=3
        )

        # è¿‡æ»¤å‡ºæŒ‡å®šæ–‡æ¡£çš„ç»“æœ
        doc_results = [r for r in results if r[metadata].get(file_id) == request.documentId]

        if not doc_results
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŒ‡å®šæ–‡æ¡£ï¼Œä½¿ç”¨æ‰€æœ‰ç»“æœ
            doc_results = results

        # æ„å»ºä¸Šä¸‹æ–‡
        context = nn.join([r[content] for r in doc_results[3]])

        # ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”
        try
            from langchain_openai import ChatOpenAI

            llm = ChatOpenAI(
                model_name=self.infermodel_name,
                api_key=self.infermodel_api_key,
                base_url=self.model_url,
                temperature=0.3
            )

            prompt = f
                åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š
    
                æ–‡æ¡£å†…å®¹ï¼š
                {context}
                
                é—®é¢˜ï¼š{request.question}
                
                è¯·ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ï¼Œå¹¶æŒ‡å‡ºå›ç­”ä¾æ®çš„å†…å®¹æ¥è‡ªå“ªäº›éƒ¨åˆ†ã€‚
            

            response = await llm.ainvoke(prompt)
            answer = response.content

            # æå–å¼•ç”¨
            citations = [i + 1 for i in range(len(doc_results))]

            logger.info(fâœ“ å›ç­”ç”Ÿæˆå®Œæˆ)

            return FollowUpQuestionResponse(
                answer=answer,
                citations=citations,
                confidence=0.85
            )

        except Exception as e
            logger.error(fâŒ å›ç­”ç”Ÿæˆå¤±è´¥ {e})
            return FollowUpQuestionResponse(
                answer=æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚,
                citations=[],
                confidence=0.0
            )

    def _extract_structured_data(self, metadata Dict[str, Any]) - List[Dict[str, str]]
        ä»å…ƒæ•°æ®æå–ç»“æ„åŒ–æ•°æ®
        structured_data = []

        if page_count in metadata
            structured_data.append({
                label é¡µæ•°,
                value str(metadata[page_count])
            })

        if version in metadata
            structured_data.append({
                label ç‰ˆæœ¬,
                value metadata[version]
            })

        if upload_date in metadata
            structured_data.append({
                label ä¸Šä¼ æ—¥æœŸ,
                value metadata[upload_date][10]
            })

        return structured_data

    async def handle_intelligent_qa(
            self,
            request IntelligentQARequest
    ) - IntelligentQAResponse
        
        æ™ºèƒ½é—®ç­” - ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜

        æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†ç­–ç•¥ï¼š
        1. ç²¾ç¡®æŸ¥è¯¢ï¼šä»å…ƒæ•°æ®ç›´æ¥æå–ç­”æ¡ˆï¼ˆå¦‚ï¼šæœ‰å‡ ä¸ªå§å®¤ï¼‰
        2. è¿‡æ»¤æŸ¥è¯¢ï¼šå…ˆè¿‡æ»¤å†æ£€ç´¢ï¼ˆå¦‚ï¼šæ‰¾3ä¸ªå§å®¤çš„æˆ·å‹ï¼‰
        3. ä¸€èˆ¬æŸ¥è¯¢ï¼šå‘é‡æ£€ç´¢ + LLMç”Ÿæˆç­”æ¡ˆ
        
        logger.info(fn{'='  60})
        logger.info(fğŸ¤– æ™ºèƒ½é—®ç­”)
        logger.info(f  é—®é¢˜ {request.question})
        logger.info(f{'='  60})

        # 1. åˆ†ç±»é—®é¢˜ç±»å‹
        query_type = self._classify_question(request.question)
        logger.info(f  é—®é¢˜ç±»å‹ {query_type})

        answer, sources, confidence = await self._handle_general_query(request.question, request.top_k)

        logger.info(fâœ“ ç­”æ¡ˆå·²ç”Ÿæˆ)
        logger.info(f  ç½®ä¿¡åº¦ {confidence.2f})
        logger.info(f  æ¥æºæ•° {len(sources)})

        return IntelligentQAResponse(
            answer=answer,
            sources=sources,
            confidence=confidence,
            query_type=query_type
        )

    def _classify_question(self, question str) - str
        åˆ†ç±»é—®é¢˜ç±»å‹
        question_lower = question.lower()

        # ç²¾ç¡®æŸ¥è¯¢å…³é”®è¯
        exact_keywords = [] # è¿™é‡Œæœªå¼€å¯ç²¾ç¡®æŸ¥è¯¢
        # exact_keywords = [å‡ ä¸ª, å¤šå°‘ä¸ª, æœ‰å¤šå°‘, é¢ç§¯, å°ºå¯¸, é•¿åº¦, å®½åº¦, å¤šå¤§, å¤šé•¿]
        if any(kw in question for kw in exact_keywords)
            return exact_query

        # è¿‡æ»¤æŸ¥è¯¢å…³é”®è¯
        filter_keywords = [] # ä¸è¿›è¡Œè¿‡æ»¤æŸ¥æ‰¾
        # filter_keywords = [æ‰¾, æŸ¥æ‰¾, ç­›é€‰, ç¬¦åˆ, æ»¡è¶³, å¤§äº, å°äº, è‡³å°‘]
        if any(kw in question for kw in filter_keywords)
            return filter_query

        return general_query


    async def _handle_general_query(
            self,
            question str,
            top_k int
    ) - tuple[str, List[Dict[str, Any]], float]
        å¤„ç†ä¸€èˆ¬æŸ¥è¯¢ - å‘é‡æ£€ç´¢ + LLM

        # å‘é‡æ£€ç´¢
        vector_results = await self.vector_manager.search(
            query=question,
            top_k=top_k
        )

    # if not vector_results
    #         return æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚, [], 0.0

        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for i, result in enumerate(vector_results, 1)
            metadata = result[metadata]
            context_parts.append(f[æ–‡æ¡£{i}] {metadata.get('file_name')})
            context_parts.append(result[content][500])
            context_parts.append()

        context = n.join(context_parts)

        # ä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        if self.infermodel_api_key
            try
                from langchain_openai import ChatOpenAI

                llm = ChatOpenAI(
                    model_name=self.infermodel_name,
                    api_key=self.infermodel_api_key,
                    base_url=self.model_url,
                    temperature=0.3
                )

                prompt = fåŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚

                    æ–‡æ¡£å†…å®¹ï¼š
                    {context}
                    
                    é—®é¢˜ï¼š{question}
                    
                    è¯·ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚
                

                response = await llm.ainvoke(prompt)
                answer = response.content

                # æ·»åŠ æ¥æº
                sources_text = nnğŸ“„ å‚è€ƒæ¥æºï¼šn
                for i, result in enumerate(vector_results, 1)
                    sources_text += f{i}. {result['metadata'].get('file_name')}n

                answer += sources_text

            except Exception as e
                logger.error(fLLMç”Ÿæˆç­”æ¡ˆå¤±è´¥ {e})
                answer = fæ ¹æ®æ£€ç´¢åˆ°çš„å†…å®¹ï¼šnn{vector_results[0]['content'][500]}nnæ¥æºï¼š{vector_results[0]['metadata'].get('file_name')}
        else
            # æ²¡æœ‰é…ç½®LLMï¼Œè¿”å›æœ€ç›¸å…³çš„å†…å®¹
            answer = fæ ¹æ®æ£€ç´¢åˆ°çš„å†…å®¹ï¼šnn{vector_results[0]['content'][500]}nnæ¥æºï¼š{vector_results[0]['metadata'].get('file_name')}

        # æ„å»ºæ¥æºä¿¡æ¯
        sources = [{
            file_id r[metadata].get(file_id),
            file_name r[metadata].get(file_name),
            file_type r[metadata].get(file_type),
            similarity r[similarity]
        } for r in vector_results]

        confidence = vector_results[0][similarity]

        return answer, sources, confidence


-----------------è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶--------------
class RequestLoggerMiddleware(BaseHTTPMiddleware)
    è®°å½•æ‰€æœ‰APIè¯·æ±‚çš„ä¸­é—´ä»¶

    async def dispatch(self, request Request, call_next)
        # è®°å½•è¯·æ±‚ä¿¡æ¯
        request_id = str(uuid.uuid4())[8]
        start_time = time.time()

        # è·å–å®¢æˆ·ç«¯ä¿¡æ¯
        client_host = request.client.host if request.client else unknown

        # è®°å½•è¯·æ±‚å¼€å§‹
        logger.info(f)
        logger.info(f{'='  80})
        logger.info(f[{request_id}]   æ”¶åˆ°è¯·æ±‚)
        logger.info(f[{request_id}]   æ–¹æ³• {request.method})
        logger.info(f[{request_id}]   è·¯å¾„ {request.url.path})
        logger.info(f[{request_id}]   å®¢æˆ·ç«¯ {client_host})
        logger.info(f[{request_id}]   User-Agent {request.headers.get('user-agent', 'NA')})

        # å¦‚æœæ˜¯ POST è¯·æ±‚ï¼Œè®°å½• Content-Type
        if request.method == POST
            content_type = request.headers.get('content-type', 'NA')
            logger.info(f[{request_id}]   Content-Type {content_type})

        logger.info(f{'='  80})

        # å¤„ç†è¯·æ±‚
        try
            response = await call_next(request)

            # è®¡ç®—è€—æ—¶
            process_time = time.time() - start_time

            # è®°å½•å“åº”
            logger.info(f)
            logger.info(f{'='  80})
            logger.info(f[{request_id}]   è¿”å›å“åº”)
            logger.info(f[{request_id}]   çŠ¶æ€ç  {response.status_code})
            logger.info(f[{request_id}]   è€—æ—¶ {process_time.3f}ç§’)
            logger.info(f{'='  80})
            logger.info(f)

            # æ·»åŠ å“åº”å¤´
            response.headers[X-Request-ID] = request_id
            response.headers[X-Process-Time] = f{process_time.3f}

            return response

        except Exception as e
            # è®°å½•é”™è¯¯
            process_time = time.time() - start_time
            logger.error(f)
            logger.error(f{'='  80})
            logger.error(f[{request_id}] âŒ è¯·æ±‚å¤„ç†å¤±è´¥)
            logger.error(f[{request_id}]   é”™è¯¯ {str(e)})
            logger.error(f[{request_id}]   è€—æ—¶ {process_time.3f}ç§’)
            logger.error(f{'='  80})
            logger.error(f, exc_info=True)
            raise



-------------FastAPI åº”ç”¨----------------

app = FastAPI(
    title=å¤šæ¨¡æ€ RAG API,
    description=é¢å‘é¥æ„Ÿå¤„ç†å¯è§†åŒ–çš„å¤šæ¨¡æ€(PDFå›¾ç‰‡æ–‡æœ¬)æ–‡æ¡£æ£€ç´¢ä¸é—®ç­”ç³»ç»Ÿ,
    version=1.0.0
)

# æ·»åŠ è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
app.add_middleware(RequestLoggerMiddleware)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=[],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=[],
    allow_headers=[],
)

# åˆå§‹åŒ–æœåŠ¡
service = MultiModalRAGService()

@app.get()
async def root()
    æ ¹è·¯å¾„
    return {
        service å¤šæ¨¡æ€ RAG API,
        version 1.0.0,
        status running
    }

@app.get(health)
async def health_check()
    å¥åº·æ£€æŸ¥
    return {
        status healthy,
        timestamp datetime.now().isoformat()
    }

@app.post(search, response_model=SearchResponse)
async def search(request SearchRequest)
    æœç´¢æ¥å£
    try
        log_request(fn{'='  80})
        log_request(f  APIæ”¶åˆ°æœç´¢è¯·æ±‚)
        log_request(f  æŸ¥è¯¢ {request.query})
        log_request(f  æ¨¡å‹ {request.model})
        log_request(f  ç­–ç•¥ {request.strategy})
        log_request(f  TopK {request.topK})
        print(f{'='  80}n)
        sys.stdout.flush()

        result = await service.handle_search(request)

        log_request(fn{'='  80})
        log_request(f  APIæœç´¢å®Œæˆï¼Œè¿”å› {result.totalCount} ä¸ªç»“æœ)
        print(f{'='  80}n)
        sys.stdout.flush()

        return result
    except Exception as e
        print(fnâŒ æœç´¢å¤±è´¥ {e}n)
        sys.stdout.flush()
        logger.error(fâŒ æœç´¢å¤±è´¥ {e})
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post(upload, response_model=UploadResponse)
async def upload(
        file UploadFile = File(...),
        image_type Optional[str] = None)
    
    æ–‡ä»¶ä¸Šä¼ æ¥å£

    Args
        file ä¸Šä¼ çš„æ–‡ä»¶
        image_type å¯é€‰çš„å›¾ç‰‡ç±»å‹æŒ‡å®š
                   æ”¯æŒ cad, floor_plan, architecture, technical_doc
    
    try
        log_request(fn{'='  80})
        log_request(fğŸ“¤ APIæ”¶åˆ°æ–‡ä»¶ä¸Šä¼ è¯·æ±‚)
        log_request(f  æ–‡ä»¶å {file.filename})
        log_request(f  Content-Type {file.content_type})
        if image_type
            log_request(f  æŒ‡å®šç±»å‹ {image_type})
        print(f{'='  80}n)
        sys.stdout.flush()

        result = await service.handle_upload(file, image_type)

        log_request(fn{'='  80})
        print(f{'âœ“' if result.success else 'âŒ'} æ–‡ä»¶ä¸Šä¼ {'æˆåŠŸ' if result.success else 'å¤±è´¥'})
        log_request(f  æ¶ˆæ¯ {result.message})
        if result.detectedImageType
            log_request(f  æ£€æµ‹ç±»å‹ {result.detectedImageType})
        print(f{'='  80}n)
        sys.stdout.flush()

        return result
    except Exception as e
        print(fnâŒ ä¸Šä¼ å¤±è´¥ {e}n)
        sys.stdout.flush()
        logger.error(fâŒ ä¸Šä¼ å¤±è´¥ {e})
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post(question, response_model=FollowUpQuestionResponse)
async def follow_up_question(request FollowUpQuestionRequest)
    è¿½é—®æ¥å£
    try
        return await service.handle_follow_up_question(request)
    except Exception as e
        logger.error(fâŒ è¿½é—®å¤±è´¥ {e})
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post(ask, response_model=IntelligentQAResponse)
async def intelligent_qa(request IntelligentQARequest)
    
    æ™ºèƒ½é—®ç­”æ¥å£ - ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜

    æ”¯æŒä¸‰ç§æŸ¥è¯¢ç±»å‹ï¼š
    1. ç²¾ç¡®æŸ¥è¯¢ï¼šä»å…ƒæ•°æ®ç›´æ¥æå–ç­”æ¡ˆï¼ˆå¦‚ï¼šæœ‰å‡ ä¸ªå§å®¤ï¼Ÿï¼‰
    2. è¿‡æ»¤æŸ¥è¯¢ï¼šæ™ºèƒ½è¿‡æ»¤ + æ£€ç´¢ï¼ˆå¦‚ï¼šæ‰¾3ä¸ªå§å®¤çš„æˆ·å‹ï¼‰
    3. ä¸€èˆ¬æŸ¥è¯¢ï¼šå‘é‡æ£€ç´¢ + LLMç”Ÿæˆç­”æ¡ˆ
    
    try
        log_request(fn{'='  80})
        log_request(fğŸ¤– APIæ”¶åˆ°æ™ºèƒ½é—®ç­”è¯·æ±‚)
        log_request(f  é—®é¢˜ {request.question})
        log_request(f  TopK {request.top_k})
        print(f{'='  80}n)
        sys.stdout.flush()

        result = await service.handle_intelligent_qa(request)

        log_request(fn{'='  80})
        log_request(fâœ“ ç­”æ¡ˆå·²ç”Ÿæˆ)
        log_request(f  é—®é¢˜ç±»å‹ {result.query_type})
        log_request(f  ç½®ä¿¡åº¦ {result.confidence.2f})
        log_request(f  æ¥æºæ•° {len(result.sources)})
        print(f{'='  80}n)
        sys.stdout.flush()

        return result
    except Exception as e
        print(fnâŒ æ™ºèƒ½é—®ç­”å¤±è´¥ {e}n)
        sys.stdout.flush()
        logger.error(fâŒ æ™ºèƒ½é—®ç­”å¤±è´¥ {e})
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get(preview{file_id})
async def get_preview(file_id str)
    è·å–æ–‡æ¡£é¢„è§ˆ
    # é¢„è§ˆå’Œç¼©ç•¥å›¾æš‚æ—¶ä¸€æ ·ï¼Œè¿”å›åŸå›¾
    return await get_thumbnail(file_id)

@app.get(thumbnail{file_id})
async def get_thumbnail(file_id str)
    è·å–æ–‡æ¡£ç¼©ç•¥å›¾
    try
        # æŸ¥æ‰¾æ–‡ä»¶
        for ext in ['.png', '.jpg', '.jpeg', '.pdf']
            file_path = service.load_dir  f{file_id}{ext}
            if file_path.exists()
                # å¯¹äºå›¾ç‰‡ï¼Œç›´æ¥è¿”å›åŸå›¾
                if ext in ['.png', '.jpg', '.jpeg']
                    return FileResponse(file_path, media_type=fimage{ext[1]})
                # å¯¹äºPDFï¼Œè¿”å›ç¼©ç•¥å›¾
                elif ext == '.pdf'
                    thumbnail_path = service.preview_dir  f{file_id}_thumb.png
                    if thumbnail_path.exists()
                        return FileResponse(thumbnail_path, media_type=imagepng)
                    else
                        # å¦‚æœç¼©ç•¥å›¾ä¸å­˜åœ¨ï¼Œå°è¯•ç”Ÿæˆ
                        thumb_path = service._generate_pdf_thumbnail(file_path, file_id)
                        if thumb_path and thumb_path.exists()
                            return FileResponse(thumb_path, media_type=imagepng)
                        else
                            raise HTTPException(status_code=500, detail=PDFç¼©ç•¥å›¾ç”Ÿæˆå¤±è´¥)
                else
                    raise HTTPException(status_code=501, detail=è¯¥æ–‡ä»¶ç±»å‹æš‚ä¸æ”¯æŒç¼©ç•¥å›¾)

        raise HTTPException(status_code=404, detail=fæ–‡ä»¶ä¸å­˜åœ¨ {file_id})
    except HTTPException
        raise
    except Exception as e
        logger.error(fè·å–ç¼©ç•¥å›¾å¤±è´¥ {e})
        raise HTTPException(status_code=500, detail=str(e))

@app.get(download{document_id})
async def download_document(document_id str)
    ä¸‹è½½æ–‡æ¡£
    # TODO å®ç°æ–‡æ¡£ä¸‹è½½
    raise HTTPException(status_code=501, detail=ä¸‹è½½åŠŸèƒ½æš‚æœªå®ç°)

# ============ å¯åŠ¨æœåŠ¡ ============

if __name__ == __main__
    print(n + =  60)
    print(ğŸš€ å¯åŠ¨å¤šæ¨¡æ€ RAG æœåŠ¡)
    print(=  60 + n)

    # é…ç½® uvicorn æ—¥å¿—
    log_config = uvicorn.config.LOGGING_CONFIG
    log_config[formatters][default][fmt] = %(message)s
    log_config[formatters][access][fmt] = '%(client_addr)s - %(request_line)s %(status_code)s'

    uvicorn.run(
        app,
        host=0.0.0.0,
        port=8000,
        log_level=info,
        log_config=log_config,
        access_log=True
    )
ä¸Šè¿°ä»£ç ï¼Œæˆ‘æ·»åŠ äº†è¿™ä¸€æ®µä»£ç ï¼šâ€œ# å¦‚æœæ²¡æœ‰åœ¨æœ¬åœ°å‘é‡æ•°æ®åº“æ£€ç´¢åˆ°ä»»ä½•å†…å®¹
        if not vector_results
            print(hhhhhhhhhhhhhhhhhhh)
            from openai import OpenAI
            client = OpenAI(
                api_key=os.getenv(QWEN_API_KEY),
                base_url=os.getenv(QWEN_BASE_URL),
            )
            res = client.chat.completions.create(
                model=os.getenv(QWEN_MULTIMODAL_MODAL_NAME),
                messages=[
                    {role system,
                     content ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¥æ„Ÿé¢†åŸŸçŸ¥è¯†ä¸äº¤å·®å­¦ç§‘ä¸“å®¶ï¼Œç°åœ¨ç§æœ‰æ•°æ®åº“ä¸­æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³ä¿¡æ¯ï¼Œå…ˆå’Œç”¨æˆ·æ¾„æ¸…è¿™ä¸€ç‚¹ï¼Œç„¶åæ¥ç€æ¾„æ¸…è‡ªå·±å°†é€šè¿‡è‡ªå·±çš„ç°æœ‰çŸ¥è¯†å›ç­”é—®é¢˜},
                    {role user, content question}
                ]
            )
            return SearchResponse(
            results=res.choices[0].message.content,
            queryTime=os.times(),  # è½¬æ¢ä¸ºæ¯«ç§’
            model=request.model,
            strategy=request.strategy
        )â€ï¼Œå¾—åˆ°æŠ¥é”™å¦‚ä¸‹ï¼šâ€œâŒ æœç´¢å¤±è´¥ 3 validation errors for SearchResponse 
results
  Input should be a valid list [type=list_type, input_value='æ‚¨å¥½ï¼Œç›®å‰æˆ‘æ— æ³•...çš„è¿›ä¸€æ­¥æé—®ï¼', input_type=str]
    For further information visit httpserrors.pydantic.dev2.12vlist_type
totalCount
  Field required [type=missing, input_value={'results' 'æ‚¨å¥½ï¼Œç›®...', 'strategy' 'hybrid'}, input_type=dict]
    For further information visit httpserrors.pydantic.dev2.12vmissing
queryTime
  Input should be a valid number [type=float_type, input_value=nt.times_result(user=3.35...system=0.0, elapsed=0.0), input_type=times_result]
    For further information visit httpserrors.pydantic.dev2.12vfloat_type

2025-10-19 160306 - root - ERROR - âŒ æœç´¢å¤±è´¥ 3 validation errors for SearchResponse
results
  Input should be a valid list [type=list_type, input_value='æ‚¨å¥½ï¼Œç›®å‰æˆ‘æ— æ³•...çš„è¿›ä¸€æ­¥æé—®ï¼', input_type=str]
    For further information visit httpserrors.pydantic.dev2.12vlist_type
totalCount
  Field required [type=missing, input_value={'results' 'æ‚¨å¥½ï¼Œç›®...', 'strategy' 'hybrid'}, input_type=dict]
    For further information visit httpserrors.pydantic.dev2.12vmissing
queryTime
  Input should be a valid number [type=float_type, input_value=nt.times_result(user=3.35...system=0.0, elapsed=0.0), input_type=times_result]
    For further information visit httpserrors.pydantic.dev2.12vfloat_type
--- Logging error ---
Traceback (most recent call last)
  File DPython3.11.9Liblogging__init__.py, line 1113, in emit
    stream.write(msg + self.terminator)
UnicodeEncodeError 'gbk' codec can't encode character 'u2713' in position 36 illegal multibyte sequence
Call stack
  File DPycharm_projectmy_multimodal_RAGbackendmain_service.py, line 1484, in module
    uvicorn.run(
  File DPython3.11.9envaqenv2Libsite-packagesuvicornmain.py, line 593, in run
    server.run()
  File DPython3.11.9envaqenv2Libsite-packagesuvicornserver.py, line 67, in run
    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())
  File DPython3.11.9envaqenv2Libsite-packagesuvicorn_compat.py, line 23, in asyncio_run
    return runner.run(main)
  File DPython3.11.9Libasynciorunners.py, line 118, in run
    return self._loop.run_until_complete(task)
  File DPython3.11.9Libasynciobase_events.py, line 641, in run_until_complete
    self.run_forever()
  File DPython3.11.9Libasynciowindows_events.py, line 321, in run_forever
    super().run_forever()
  File DPython3.11.9Libasynciobase_events.py, line 608, in run_forever
    self._run_once()
  File DPython3.11.9Libasynciobase_events.py, line 1936, in _run_once
    handle._run()
  File DPython3.11.9Libasyncioevents.py, line 84, in _run
    self._context.run(self._callback, self._args)
  File DPython3.11.9envaqenv2Libsite-packagesstarlettemiddlewarebase.py, line 144, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File DPython3.11.9envaqenv2Libsite-packagesstarlettemiddlewareexceptions.py, line 63, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarlette_exception_handler.py, line 42, in wrapped_app
    await app(scope, receive, sender)
  File DPython3.11.9envaqenv2Libsite-packagesfastapimiddlewareasyncexitstack.py, line 18, in __call__
    await self.app(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarletterouting.py, line 716, in __call__
    await self.middleware_stack(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarletterouting.py, line 736, in app
    await route.handle(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarletterouting.py, line 290, in handle
    await self.app(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesfastapirouting.py, line 123, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarlette_exception_handler.py, line 42, in wrapped_app
    await app(scope, receive, sender)
  File DPython3.11.9envaqenv2Libsite-packagesfastapirouting.py, line 109, in app
    response = await f(request)
  File DPython3.11.9envaqenv2Libsite-packagesfastapirouting.py, line 387, in app
    raw_response = await run_endpoint_function(
  File DPython3.11.9envaqenv2Libsite-packagesfastapirouting.py, line 288, in run_endpoint_function
    return await dependant.call(values)
  File DPycharm_projectmy_multimodal_RAGbackendmain_service.py, line 1322, in search
    result = await service.handle_search(request)
  File DPycharm_projectmy_multimodal_RAGbackendmain_service.py, line 664, in handle_search
    vector_results = await self.vector_manager.search(
  File DPycharm_projectmy_multimodal_RAGbackendmain_service.py, line 284, in search
    logger.info(fâœ“ æ‰¾åˆ° {len(formatted_results)} ä¸ªç›¸å…³ç»“æœ)
Message 'âœ“ æ‰¾åˆ° 0 ä¸ªç›¸å…³ç»“æœ'
Arguments ()
--- Logging error ---
Traceback (most recent call last)
  File DPycharm_projectmy_multimodal_RAGbackendmain_service.py, line 1322, in search
    result = await service.handle_search(request)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File DPycharm_projectmy_multimodal_RAGbackendmain_service.py, line 685, in handle_search
    return SearchResponse(
           ^^^^^^^^^^^^^^^
  File DPython3.11.9envaqenv2Libsite-packagespydanticmain.py, line 250, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError 3 validation errors for SearchResponse
results
  Input should be a valid list [type=list_type, input_value='æ‚¨å¥½ï¼Œç›®å‰æˆ‘æ— æ³•...çš„è¿›ä¸€æ­¥æé—®ï¼', input_type=str]
    For further information visit httpserrors.pydantic.dev2.12vlist_type
totalCount
  Field required [type=missing, input_value={'results' 'æ‚¨å¥½ï¼Œç›®...', 'strategy' 'hybrid'}, input_type=dict]
    For further information visit httpserrors.pydantic.dev2.12vmissing
queryTime
  Input should be a valid number [type=float_type, input_value=nt.times_result(user=3.35...system=0.0, elapsed=0.0), input_type=times_result]
    For further information visit httpserrors.pydantic.dev2.12vfloat_type

During handling of the above exception, another exception occurred

Traceback (most recent call last)
  File DPython3.11.9Liblogging__init__.py, line 1113, in emit
    stream.write(msg + self.terminator)
UnicodeEncodeError 'gbk' codec can't encode character 'u274c' in position 37 illegal multibyte sequence
Call stack
  File DPycharm_projectmy_multimodal_RAGbackendmain_service.py, line 1484, in module
    uvicorn.run(
  File DPython3.11.9envaqenv2Libsite-packagesuvicornmain.py, line 593, in run
    server.run()
  File DPython3.11.9envaqenv2Libsite-packagesuvicornserver.py, line 67, in run
    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())
  File DPython3.11.9envaqenv2Libsite-packagesuvicorn_compat.py, line 23, in asyncio_run
    return runner.run(main)
  File DPython3.11.9Libasynciorunners.py, line 118, in run
    return self._loop.run_until_complete(task)
  File DPython3.11.9Libasynciobase_events.py, line 641, in run_until_complete
    self.run_forever()
  File DPython3.11.9Libasynciowindows_events.py, line 321, in run_forever
    super().run_forever()
  File DPython3.11.9Libasynciobase_events.py, line 608, in run_forever
    self._run_once()
  File DPython3.11.9Libasynciobase_events.py, line 1936, in _run_once
    handle._run()
  File DPython3.11.9Libasyncioevents.py, line 84, in _run
    self._context.run(self._callback, self._args)
  File DPython3.11.9envaqenv2Libsite-packagesstarlettemiddlewarebase.py, line 144, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File DPython3.11.9envaqenv2Libsite-packagesstarlettemiddlewareexceptions.py, line 63, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarlette_exception_handler.py, line 42, in wrapped_app
    await app(scope, receive, sender)
  File DPython3.11.9envaqenv2Libsite-packagesfastapimiddlewareasyncexitstack.py, line 18, in __call__
    await self.app(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarletterouting.py, line 716, in __call__
    await self.middleware_stack(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarletterouting.py, line 736, in app
    await route.handle(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesstarletterouting.py, line 290, in handle
    await self.app(scope, receive, send)
  File DPython3.11.9envaqenv2Libsite-packagesfastapirouting.py, line 123, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)â€